<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.4">Jekyll</generator><link href="http://localhost:4000/gremlin-blog-posts/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/gremlin-blog-posts/" rel="alternate" type="text/html" /><updated>2018-11-25T18:56:48-08:00</updated><id>http://localhost:4000/gremlin-blog-posts/feed.xml</id><title type="html">Gremlin: Blog Posts</title><subtitle>An amazing website.</subtitle><author><name>Gabe Wyatt</name></author><entry><title type="html">Chaos Engineering Through Staged Resiliency - Stage 3</title><link href="http://localhost:4000/gremlin-blog-posts/chaos-engineering/chaos-engineering-through-staged-resiliency-stage-3/" rel="alternate" type="text/html" title="Chaos Engineering Through Staged Resiliency - Stage 3" /><published>2018-10-11T00:00:00-07:00</published><updated>2018-10-11T00:00:00-07:00</updated><id>http://localhost:4000/gremlin-blog-posts/chaos-engineering/chaos-engineering-through-staged-resiliency-stage-3</id><content type="html" xml:base="http://localhost:4000/gremlin-blog-posts/chaos-engineering/chaos-engineering-through-staged-resiliency-stage-3/">&lt;p&gt;Performing occasional, manual resiliency testing is useful, but your system must be automatically and frequently tested to provide any real sense of stability.  In &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-2&quot;&gt;Chaos Engineering Through Staged Resiliency - Stage 2&lt;/a&gt; we focused on critical dependency failure testing in non-production environments.  To work through &lt;strong&gt;Resiliency Stage 3&lt;/strong&gt; your team will need to begin automating these test and experiments.  This allows the testing frequency to improve dramatically and reduces the reliance manual processes.&lt;/p&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Creation and agreement on [Disaster Recovery and Dependency Failover Playbooks][#stage-1#prerequisites].&lt;/li&gt;
  &lt;li&gt;Completion of &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-1&quot;&gt;Resiliency Stage 1&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Completion of &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-2&quot;&gt;Resiliency Stage 2&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;perform-frequent-semi-automated-tests&quot;&gt;Perform Frequent, Semi-Automated Tests&lt;/h2&gt;

&lt;p&gt;There’s no more putting it off – it’s time to begin automating your testing procedures.  During this third &lt;strong&gt;Resiliency Stage&lt;/strong&gt; the team should aim to automate as much of the resiliency testing process as reasonably possible.  The overall goal of this stage isn’t to finalize automation, but to work toward a regular cadence of testing.  The frequency of each test is up to the team, but once established it’s critical that the schedule is maintained and automation handles at least &lt;em&gt;some&lt;/em&gt; of the testing process.&lt;/p&gt;

&lt;p&gt;If the team isn’t already doing so, this is a prime opportunity to introduce Chaos Engineering tools.  These tools empower the team to intelligently create controlled experiments that can be executed precisely when necessary.  For example, Gremlin attacks can be &lt;a href=&quot;https://help.gremlin.com/attacks/#how-to-schedule-attacks-with-gremlin&quot;&gt;scheduled&lt;/a&gt; to execute on certain days of the week and within a specified window of time.&lt;/p&gt;

&lt;h2 id=&quot;execute-a-resiliency-experiment-in-production&quot;&gt;Execute a Resiliency Experiment in Production&lt;/h2&gt;

&lt;p&gt;Resiliency experiments in non-production are beneficial, but a system is never truly being properly tested unless you’re willing to perform experiments in production.  Use of internal or third-party Chaos Engineering tools can help with the process of executing a resiliency experiment in production.  A tool that configures and executes a given experiment can be used to &lt;em&gt;repeat&lt;/em&gt; that experiment over and over, without introducing any issues that may normally be introduced due to human intervention.  As experiments are performed and the results evaluated, observability will improve, playbooks are updated, and overall support costs are reduced.&lt;/p&gt;

&lt;h2 id=&quot;publish-test-results&quot;&gt;Publish Test Results&lt;/h2&gt;

&lt;p&gt;As you’ve been doing thus far, you must continue publishing test results to the entire team.  This step is &lt;em&gt;especially&lt;/em&gt; critical now that experiments are being performed in production.&lt;/p&gt;

&lt;h2 id=&quot;resiliency-stage-3-implementation-example&quot;&gt;Resiliency Stage 3: Implementation Example&lt;/h2&gt;

&lt;h3 id=&quot;how-to-automate-bluegreen-instance-failover-in-aws&quot;&gt;How to Automate Blue/Green Instance Failover in AWS&lt;/h3&gt;

&lt;p&gt;The blue/green deployment for the &lt;strong&gt;Bookstore&lt;/strong&gt; application provides two identical production environment instances of the system.  However, if the currently active instance fails we still have to manually swap DNS records from blue to green (or vice versa).  In order to meet the requirement of executing a resiliency experiment in production we need to automate this failover process.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Create a metric alarm within Amazon CloudWatch.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws cloudwatch put-metric-alarm &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--cli-input-json&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;ActionsEnabled&quot;: true,
     &quot;AlarmActions&quot;: [
         &quot;arn:aws:sns:us-west-2:532151327118:PingPublicationsSNS&quot;
     ],
     &quot;AlarmDescription&quot;: &quot;Bookstore API (Blue) instance failure.&quot;,
     &quot;AlarmName&quot;: &quot;bookstore-api-blue-StatusCheckFailed&quot;,
     &quot;ComparisonOperator&quot;: &quot;GreaterThanOrEqualToThreshold&quot;,
     &quot;DatapointsToAlarm&quot;: 1,
     &quot;Dimensions&quot;: [
         {
             &quot;Name&quot;: &quot;InstanceId&quot;,
             &quot;Value&quot;: &quot;i-0ab55a49288f1da24&quot;
         }
     ],
     &quot;EvaluationPeriods&quot;: 1,
     &quot;MetricName&quot;: &quot;StatusCheckFailed&quot;,
     &quot;Namespace&quot;: &quot;AWS/EC2&quot;,
     &quot;Period&quot;: 60,
     &quot;Statistic&quot;: &quot;Maximum&quot;,
     &quot;Threshold&quot;: 1.0,
     &quot;TreatMissingData&quot;: &quot;breaching&quot;
 }'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;The above configuration checks the &lt;code class=&quot;highlighter-rouge&quot;&gt;StatusCheckFailed&lt;/code&gt; metric once a minute, which determines if &lt;em&gt;either&lt;/em&gt; the Amazon EC2 system or the specific EC2 instance has failed.  We have to set &lt;code class=&quot;highlighter-rouge&quot;&gt;TreatMissingData&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;breaching&lt;/code&gt; so that the &lt;em&gt;absence&lt;/em&gt; of data will trigger an &lt;code class=&quot;highlighter-rouge&quot;&gt;ALARM&lt;/code&gt; state (otherwise, the instance can be &lt;code class=&quot;highlighter-rouge&quot;&gt;stopped&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;terminated&lt;/code&gt;, but the &lt;code class=&quot;highlighter-rouge&quot;&gt;StatusCheck&lt;/code&gt; will succeed).&lt;/p&gt;

    &lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;Dimensions&lt;/code&gt; array ensures this &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue-StatusCheckFailed&lt;/code&gt; alarm only checks against the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue&lt;/code&gt; instance, and the &lt;code class=&quot;highlighter-rouge&quot;&gt;AlarmActions&lt;/code&gt; specifies an Amazon SNS ARN to push an alert to when the alarm is triggered.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Next, create an Amazon Route53 Health Check that uses the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue-StatusCheckFailed&lt;/code&gt; Amazon CloudWatch alarm for its &lt;code class=&quot;highlighter-rouge&quot;&gt;healthy/unhealthy&lt;/code&gt; determination.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 create-health-check &lt;span class=&quot;nt&quot;&gt;--caller-reference&lt;/span&gt; bookstore-api-blue-health-check &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--health-check-config&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;InsufficientDataHealthStatus&quot;: &quot;Unhealthy&quot;, 
     &quot;Type&quot;: &quot;CLOUDWATCH_METRIC&quot;, 
     &quot;AlarmIdentifier&quot;: {
         &quot;Region&quot;: &quot;us-west-2&quot;, 
         &quot;Name&quot;: &quot;bookstore-api-blue-StatusCheckFailed&quot;
     }, 
     &quot;Inverted&quot;: false
 }'&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheck&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckConfig&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&quot;InsufficientDataHealthStatus&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Unhealthy&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;CLOUDWATCH_METRIC&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;AlarmIdentifier&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&quot;Region&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;us-west-2&quot;&lt;/span&gt;, 
                 &lt;span class=&quot;s2&quot;&gt;&quot;Name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-api-blue-StatusCheckFailed&quot;&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Inverted&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;CallerReference&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-api-blue-health-check&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckVersion&quot;&lt;/span&gt;: 1, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;119e6884-3685-4e5a-9520-44cebae6c734&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;CloudWatchAlarmConfiguration&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&quot;EvaluationPeriods&quot;&lt;/span&gt;: 1, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Dimensions&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
                 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                     &lt;span class=&quot;s2&quot;&gt;&quot;Name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;InstanceId&quot;&lt;/span&gt;, 
                     &lt;span class=&quot;s2&quot;&gt;&quot;Value&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;i-0ab55a49288f1da24&quot;&lt;/span&gt;
                 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Namespace&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;AWS/EC2&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Period&quot;&lt;/span&gt;: 60, 
             &lt;span class=&quot;s2&quot;&gt;&quot;ComparisonOperator&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;GreaterThanOrEqualToThreshold&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Statistic&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Maximum&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Threshold&quot;&lt;/span&gt;: 1.0, 
             &lt;span class=&quot;s2&quot;&gt;&quot;MetricName&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;StatusCheckFailed&quot;&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
     &lt;span class=&quot;s2&quot;&gt;&quot;Location&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;https://route53.amazonaws.com/2013-04-01/healthcheck/119e6884-3685-4e5a-9520-44cebae6c734&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;TIP&lt;/strong&gt;: To reduce AWS costs we’re using a 60-second metric evaluation interval here, but in a more demanding application this &lt;code class=&quot;highlighter-rouge&quot;&gt;Period&lt;/code&gt; should be significantly shorter.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Retrieve the &lt;code class=&quot;highlighter-rouge&quot;&gt;Id&lt;/code&gt; for the &lt;code class=&quot;highlighter-rouge&quot;&gt;pingpublications.com&lt;/code&gt; Amazon Route53 hosted zone.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 list-hosted-zones &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;HostedZones&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&quot;ResourceRecordSetCount&quot;&lt;/span&gt;: 5, 
             &lt;span class=&quot;s2&quot;&gt;&quot;CallerReference&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;303EC092-EDA3-C2B7-822E-5E609CA718A3&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Config&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&quot;PrivateZone&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;/hostedzone/Z2EHK3FAEUNRMI&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;pingpublications.com.&quot;&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create a pair of Amazon Route53 &lt;code class=&quot;highlighter-rouge&quot;&gt;Type: A&lt;/code&gt; DNS record sets that will perform a &lt;code class=&quot;highlighter-rouge&quot;&gt;Failover&lt;/code&gt; routing policy from the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue&lt;/code&gt; to the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-green&lt;/code&gt; production environment.  Therefore, even in the event that the blue instance fails the above health check, the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore.pingpublications.com&lt;/code&gt; endpoint will always point to an active production instance.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 change-resource-record-sets &lt;span class=&quot;nt&quot;&gt;--hosted-zone-id&lt;/span&gt; /hostedzone/Z2EHK3FAEUNRMI &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--change-batch&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;Comment&quot;: &quot;Adding bookstore.pingpublications.com failover.&quot;,
     &quot;Changes&quot;: [
         {
             &quot;Action&quot;: &quot;CREATE&quot;,
             &quot;ResourceRecordSet&quot;: {
                 &quot;Name&quot;: &quot;bookstore.pingpublications.com.&quot;,
                 &quot;Type&quot;: &quot;A&quot;,
                 &quot;SetIdentifier&quot;: &quot;bookstore-Primary&quot;,
                 &quot;Failover&quot;: &quot;PRIMARY&quot;,
                 &quot;TTL&quot;: 60,
                 &quot;ResourceRecords&quot;: [
                     {
                         &quot;Value&quot;: &quot;54.213.54.171&quot;
                     }
                 ],
                 &quot;HealthCheckId&quot;: &quot;119e6884-3685-4e5a-9520-44cebae6c734&quot;
             }
         },
         {
             &quot;Action&quot;: &quot;CREATE&quot;,
             &quot;ResourceRecordSet&quot;: {
                 &quot;Name&quot;: &quot;bookstore.pingpublications.com.&quot;,
                 &quot;Type&quot;: &quot;A&quot;,
                 &quot;SetIdentifier&quot;: &quot;bookstore-Secondary&quot;,
                 &quot;Failover&quot;: &quot;SECONDARY&quot;,
                 &quot;TTL&quot;: 60,
                 &quot;ResourceRecords&quot;: [
                     {
                         &quot;Value&quot;: &quot;52.11.79.9&quot;
                     }
                 ]
             }
         }
     ]
 }'&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;ChangeInfo&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Status&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;PENDING&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Comment&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Adding bookstore.pingpublications.com failover.&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;SubmittedAt&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-15T01:54:15.785Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;/change/C1XJ0G2FTPLYDO&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Double-check that the two failover record sets have been created.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 list-resource-record-sets &lt;span class=&quot;nt&quot;&gt;--hosted-zone-id&lt;/span&gt; /hostedzone/Z2EHK3FAEUNRMI &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;ResourceRecordSets&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckId&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;119e6884-3685-4e5a-9520-44cebae6c734&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore.pingpublications.com.&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Failover&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;PRIMARY&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;ResourceRecords&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
                 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                     &lt;span class=&quot;s2&quot;&gt;&quot;Value&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;54.213.54.171&quot;&lt;/span&gt;
                 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;TTL&quot;&lt;/span&gt;: 60, 
             &lt;span class=&quot;s2&quot;&gt;&quot;SetIdentifier&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-Primary&quot;&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
         &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&quot;Name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore.pingpublications.com.&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;A&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Failover&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;SECONDARY&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;ResourceRecords&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
                 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                     &lt;span class=&quot;s2&quot;&gt;&quot;Value&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;52.11.79.9&quot;&lt;/span&gt;
                 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;TTL&quot;&lt;/span&gt;: 60, 
             &lt;span class=&quot;s2&quot;&gt;&quot;SetIdentifier&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-Secondary&quot;&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;verifying-automated-instance-failover&quot;&gt;Verifying Automated Instance Failover&lt;/h4&gt;

&lt;p&gt;To test the failover process for the &lt;strong&gt;Bookstore&lt;/strong&gt; API application instances we’ll use a Gremlin &lt;a href=&quot;https://help.gremlin.com/attack-params-ref/#shutdown&quot;&gt;Shutdown Attack&lt;/a&gt;.  This attack will temporarily shutdown the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue&lt;/code&gt; Amazon EC2 instance.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Verify the current status of the &lt;strong&gt;Bookstore&lt;/strong&gt; API by checking the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore.pingpublications.com/version/&lt;/code&gt; endpoint.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl bookstore.pingpublications.com/version/ | jq
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;environment&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-api-blue&quot;&lt;/span&gt;,
     &lt;span class=&quot;s2&quot;&gt;&quot;version&quot;&lt;/span&gt;: 7
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;This shows what app version is running and confirms that the endpoint is pointing to the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue&lt;/code&gt; Amazon EC2 instance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Run a Gremlin Shutdown Attack targeting the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue&lt;/code&gt; Client.  Check out the &lt;a href=&quot;https://help.gremlin.com/&quot;&gt;Gremlin Help&lt;/a&gt; documentation for more details on creating attacks with Gremlin’s Chaos Engineering tools.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;After a moment the Amazon CloudWatch &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue-StatusCheckFailed&lt;/code&gt; Alarm triggers, thereby causing the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue-healthy&lt;/code&gt; Amazon Route53 health check to fail.  This automatically triggers the DNS failover created previously, which points the primary &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore.pingpublications.com&lt;/code&gt; endpoint to the &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; EC2 production environment.  Verify this failover has automatically propagated by checking the &lt;code class=&quot;highlighter-rouge&quot;&gt;/version/&lt;/code&gt; endpoint once again.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl bookstore.pingpublications.com/version/ | jq
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;environment&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-api-green&quot;&lt;/span&gt;,
     &lt;span class=&quot;s2&quot;&gt;&quot;version&quot;&lt;/span&gt;: 7
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;how-to-generate-custom-aws-metrics&quot;&gt;How to Generate Custom AWS Metrics&lt;/h3&gt;

&lt;p&gt;Automating critical dependency failure tests often requires a way to &lt;em&gt;simulate&lt;/em&gt; the failure of critical dependencies if those dependencies are third-party and therefore out of our control.  This is the case with the &lt;strong&gt;Bookstore&lt;/strong&gt; app that relies on Amazon S3 and Amazon RDS for its CDN and database services, respectively.  Tools like Gremlin can help with this task.  Running a Gremlin &lt;strong&gt;Blackhole Attack&lt;/strong&gt; on the &lt;strong&gt;Bookstore&lt;/strong&gt; API environment can block all network communication between the API instance and specified endpoints, including those for the CDN and database.&lt;/p&gt;

&lt;p&gt;However, AWS EC2 instances don’t have any built-in capability to monitor the connectivity between said instance and another arbitrary endpoint.  Therefore, the solution is to create some &lt;em&gt;custom&lt;/em&gt; metrics that will effectively measure the “health” of the connection between the &lt;strong&gt;Bookstore&lt;/strong&gt; API instance and its critical dependencies.&lt;/p&gt;

&lt;p&gt;While AWS provides many built-in metrics, creating &lt;a href=&quot;https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html&quot;&gt;custom metrics&lt;/a&gt; requires that you explicitly generate &lt;em&gt;all&lt;/em&gt; the relevant data for said metric.  For this reason, a custom metric is little more than a combination of a metric &lt;code class=&quot;highlighter-rouge&quot;&gt;name&lt;/code&gt; and list of &lt;code class=&quot;highlighter-rouge&quot;&gt;dimensions&lt;/code&gt;, which are used as &lt;code class=&quot;highlighter-rouge&quot;&gt;key/value&lt;/code&gt; pairs to distinguish and categorize metrics.  For our purposes here we’re creating simple metrics that act as a health monitor for each critical dependency.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;We start by creating a couple bash scripts within our application code repository.  These scripts are executed from the &lt;strong&gt;Bookstore&lt;/strong&gt; API instances.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# ~/apps/bookstore_api/metrics/db-connectivity.sh&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;INSTANCE_ID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;ec2metadata &lt;span class=&quot;nt&quot;&gt;--instance-id&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;TAG_NAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;/home/ubuntu/.local/bin/aws ec2 describe-tags &lt;span class=&quot;nt&quot;&gt;--filter&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Name=resource-id,Values=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$INSTANCE_ID&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Name=key,Values=Name&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Tags[*].Value&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; text&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;while &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sleep &lt;/span&gt;10
 &lt;span class=&quot;k&quot;&gt;do
     if &lt;/span&gt;nc &lt;span class=&quot;nt&quot;&gt;-zv&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-w&lt;/span&gt; 5 db.bookstore.pingpublications.com 5432 2&amp;gt;&amp;amp;1 | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--line-buffered&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; succeeded&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt;
         /home/ubuntu/.local/bin/aws cloudwatch put-metric-data &lt;span class=&quot;nt&quot;&gt;--metric-name&lt;/span&gt; db-connectivity &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; Bookstore &lt;span class=&quot;nt&quot;&gt;--dimensions&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TAG_NAME&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--value&lt;/span&gt; 1
     &lt;span class=&quot;k&quot;&gt;else
         &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Connection to db.bookstore.pingpublications.com 5432 port [tcp/postgresql] failed!&quot;&lt;/span&gt;
         /home/ubuntu/.local/bin/aws cloudwatch put-metric-data &lt;span class=&quot;nt&quot;&gt;--metric-name&lt;/span&gt; db-connectivity &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; Bookstore &lt;span class=&quot;nt&quot;&gt;--dimensions&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TAG_NAME&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--value&lt;/span&gt; 0
     &lt;span class=&quot;k&quot;&gt;fi
 done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# ~/apps/bookstore_api/metrics/cdn-connectivity.sh&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;INSTANCE_ID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;ec2metadata &lt;span class=&quot;nt&quot;&gt;--instance-id&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;TAG_NAME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;/home/ubuntu/.local/bin/aws ec2 describe-tags &lt;span class=&quot;nt&quot;&gt;--filter&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Name=resource-id,Values=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$INSTANCE_ID&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Name=key,Values=Name&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Tags[*].Value&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; text&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;while &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sleep &lt;/span&gt;10
 &lt;span class=&quot;k&quot;&gt;do
     if &lt;/span&gt;nc &lt;span class=&quot;nt&quot;&gt;-zv&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-w&lt;/span&gt; 5 cdn.bookstore.pingpublications.com 80 2&amp;gt;&amp;amp;1 | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--line-buffered&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; succeeded&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt;
         /home/ubuntu/.local/bin/aws cloudwatch put-metric-data &lt;span class=&quot;nt&quot;&gt;--metric-name&lt;/span&gt; cdn-connectivity &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; Bookstore &lt;span class=&quot;nt&quot;&gt;--dimensions&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TAG_NAME&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--value&lt;/span&gt; 1
     &lt;span class=&quot;k&quot;&gt;else
         &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Connection to cdn.bookstore.pingpublications.com 80 port [tcp/http] failed!&quot;&lt;/span&gt;
         /home/ubuntu/.local/bin/aws cloudwatch put-metric-data &lt;span class=&quot;nt&quot;&gt;--metric-name&lt;/span&gt; cdn-connectivity &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; Bookstore &lt;span class=&quot;nt&quot;&gt;--dimensions&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TAG_NAME&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--value&lt;/span&gt; 0
     &lt;span class=&quot;k&quot;&gt;fi
 done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;To check the connectivity for the database or CDN endpoint we first retrieve the Amazon EC2 instance Id and, from that, get the &lt;code class=&quot;highlighter-rouge&quot;&gt;Name&lt;/code&gt; tag value, which is passed as the &lt;code class=&quot;highlighter-rouge&quot;&gt;Host&lt;/code&gt; dimension when creating our metric.  This &lt;code class=&quot;highlighter-rouge&quot;&gt;Host&lt;/code&gt; value specifies which environment (blue/green) is being evaluated.&lt;/p&gt;

    &lt;p class=&quot;notice--tip&quot;&gt;These scripts use &lt;a href=&quot;https://linux.die.net/man/1/nc&quot;&gt;netcat&lt;/a&gt; to check the current network connectivity between the instance and the primary critical dependency endpoint.  This check is performed every &lt;code class=&quot;highlighter-rouge&quot;&gt;10 seconds&lt;/code&gt;.  The AWS CLI then generates metric data for the &lt;code class=&quot;highlighter-rouge&quot;&gt;db-connectivity&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn-connectivity&lt;/code&gt; metrics, passing a value of &lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt; if the connection succeeded and &lt;code class=&quot;highlighter-rouge&quot;&gt;0&lt;/code&gt; for a failure.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create &lt;code class=&quot;highlighter-rouge&quot;&gt;systemd&lt;/code&gt; service configuration files so the bash scripts will be executed and remain active.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Start by creating the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db-connectivity&lt;/code&gt; service and pointing the &lt;code class=&quot;highlighter-rouge&quot;&gt;ExecStart&lt;/code&gt; command to the &lt;code class=&quot;highlighter-rouge&quot;&gt;db-connectivity.sh&lt;/code&gt; file.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;nano /etc/systemd/system/bookstore-db-connectivity.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Unit]
  &lt;span class=&quot;nv&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Bookstore Database Connectivity Service
  &lt;span class=&quot;nv&quot;&gt;After&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;network.target

  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Service]
  &lt;span class=&quot;nv&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;simple
  &lt;span class=&quot;nv&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;ubuntu
  &lt;span class=&quot;nv&quot;&gt;Group&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;ubuntu
  &lt;span class=&quot;nv&quot;&gt;WorkingDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/ubuntu
  &lt;span class=&quot;nv&quot;&gt;ExecStart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/ubuntu/apps/bookstore_api/metrics/db-connectivity.sh
  &lt;span class=&quot;nv&quot;&gt;Restart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;always

  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Install]
  &lt;span class=&quot;nv&quot;&gt;WantedBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Do the same for the CDN.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;nano /etc/systemd/system/bookstore-cdn-connectivity.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Unit]
  &lt;span class=&quot;nv&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Bookstore CDN Connectivity Service
  &lt;span class=&quot;nv&quot;&gt;After&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;network.target

  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Service]
  &lt;span class=&quot;nv&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;simple
  &lt;span class=&quot;nv&quot;&gt;User&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;ubuntu
  &lt;span class=&quot;nv&quot;&gt;Group&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;ubuntu
  &lt;span class=&quot;nv&quot;&gt;WorkingDirectory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/ubuntu
  &lt;span class=&quot;nv&quot;&gt;ExecStart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/ubuntu/apps/bookstore_api/metrics/cdn-connectivity.sh
  &lt;span class=&quot;nv&quot;&gt;Restart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;always

  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Install]
  &lt;span class=&quot;nv&quot;&gt;WantedBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;multi-user.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Set permissions such that both service target scripts are executable.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;chmod&lt;/span&gt; +x /home/ubuntu/apps/bookstore_api/metrics/db-connectivity.sh &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;chmod&lt;/span&gt; +x /home/ubuntu/apps/bookstore_api/metrics/cdn-connectivity.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Enable both services and either reboot the instance or manually start the services.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;bookstore-db-connectivity &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;bookstore-cdn-connectivity
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl start bookstore-db-connectivity &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl start bookstore-cdn-connectivity
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Verify that both services are active.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl status bookstore-db-connectivity.service 
 Loaded: loaded &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;/etc/systemd/system/bookstore-db-connectivity.service&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; disabled&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; vendor preset: enabled&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 Active: active &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;running&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; since Mon 2018-11-17 12:02:19 UTC&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 2min 3s ago

 Nov 17 12:02:42 bookstore-api-green systemd[1]: Started Bookstore Database Connectivity Service.
 Nov 17 12:02:42 bookstore-api-green db-connectivity.sh[24683]: Connection to db.bookstore.pingpublications.com 5432 port &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;tcp/postgresql] succeeded!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl status bookstore-cdn-connectivity
 Loaded: loaded &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;/etc/systemd/system/bookstore-cdn-connectivity.service&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; disabled&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; vendor preset: enabled&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 Active: active &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;running&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; since Mon 2018-11-17 12:02:19 UTC&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 20s ago

 Nov 17 12:02:19 bookstore-api-green systemd[1]: Started Bookstore CDN Connectivity Service.
 Nov 17 12:02:31 bookstore-api-green cdn-connectivity.sh[24695]: Connection to cdn.bookstore.pingpublications.com 80 port &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;tcp/http] succeeded!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create Amazon CloudWatch Alarms based on the four generated metrics.  These alarms check for a connectivity failure within the last two minutes.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; aws cloudwatch put-metric-alarm &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--cli-input-json&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;ActionsEnabled&quot;: true,
     &quot;AlarmActions&quot;: [
         &quot;arn:aws:sns:us-west-2:532151327118:PingPublicationsSNS&quot;
     ],
     &quot;AlarmDescription&quot;: &quot;Database connectivity failure for Bookstore API (Blue).&quot;,
     &quot;AlarmName&quot;: &quot;bookstore-api-blue-db-connectivity-failed&quot;,
     &quot;ComparisonOperator&quot;: &quot;LessThanThreshold&quot;,
     &quot;DatapointsToAlarm&quot;: 2,
     &quot;Dimensions&quot;: [
         {
             &quot;Name&quot;: &quot;Host&quot;,
             &quot;Value&quot;: &quot;bookstore-api-blue&quot;
         }
     ],
     &quot;EvaluationPeriods&quot;: 2,
     &quot;MetricName&quot;: &quot;db-connectivity&quot;,
     &quot;Namespace&quot;: &quot;Bookstore&quot;,
     &quot;Period&quot;: 60,
     &quot;Statistic&quot;: &quot;Average&quot;,
     &quot;Threshold&quot;: 1.0
 }'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; aws cloudwatch put-metric-alarm &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--cli-input-json&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;ActionsEnabled&quot;: true,
     &quot;AlarmActions&quot;: [
         &quot;arn:aws:sns:us-west-2:532151327118:PingPublicationsSNS&quot;
     ],
     &quot;AlarmDescription&quot;: &quot;CDN connectivity failure for Bookstore API (Blue).&quot;,
     &quot;AlarmName&quot;: &quot;bookstore-api-blue-cdn-connectivity-failed&quot;,
     &quot;ComparisonOperator&quot;: &quot;LessThanThreshold&quot;,
     &quot;DatapointsToAlarm&quot;: 2,
     &quot;Dimensions&quot;: [
         {
             &quot;Name&quot;: &quot;Host&quot;,
             &quot;Value&quot;: &quot;bookstore-api-blue&quot;
         }
     ],
     &quot;EvaluationPeriods&quot;: 2,
     &quot;MetricName&quot;: &quot;cdn-connectivity&quot;,
     &quot;Namespace&quot;: &quot;Bookstore&quot;,
     &quot;Period&quot;: 60,
     &quot;Statistic&quot;: &quot;Average&quot;,
     &quot;Threshold&quot;: 1.0
 }'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; aws cloudwatch put-metric-alarm &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--cli-input-json&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;ActionsEnabled&quot;: true,
     &quot;AlarmActions&quot;: [
         &quot;arn:aws:sns:us-west-2:532151327118:PingPublicationsSNS&quot;
     ],
     &quot;AlarmDescription&quot;: &quot;Database connectivity failure for Bookstore API (Green).&quot;,
     &quot;AlarmName&quot;: &quot;bookstore-api-green-db-connectivity-failed&quot;,
     &quot;ComparisonOperator&quot;: &quot;LessThanThreshold&quot;,
     &quot;DatapointsToAlarm&quot;: 2,
     &quot;Dimensions&quot;: [
         {
             &quot;Name&quot;: &quot;Host&quot;,
             &quot;Value&quot;: &quot;bookstore-api-green&quot;
         }
     ],
     &quot;EvaluationPeriods&quot;: 2,
     &quot;MetricName&quot;: &quot;db-connectivity&quot;,
     &quot;Namespace&quot;: &quot;Bookstore&quot;,
     &quot;Period&quot;: 60,
     &quot;Statistic&quot;: &quot;Average&quot;,
     &quot;Threshold&quot;: 1.0
 }'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; aws cloudwatch put-metric-alarm &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--cli-input-json&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;ActionsEnabled&quot;: true,
     &quot;AlarmActions&quot;: [
         &quot;arn:aws:sns:us-west-2:532151327118:PingPublicationsSNS&quot;
     ],
     &quot;AlarmDescription&quot;: &quot;CDN connectivity failure for Bookstore API (Green).&quot;,
     &quot;AlarmName&quot;: &quot;bookstore-api-green-cdn-connectivity-failed&quot;,
     &quot;ComparisonOperator&quot;: &quot;LessThanThreshold&quot;,
     &quot;DatapointsToAlarm&quot;: 2,
     &quot;Dimensions&quot;: [
         {
             &quot;Name&quot;: &quot;Host&quot;,
             &quot;Value&quot;: &quot;bookstore-api-green&quot;
         }
     ],
     &quot;EvaluationPeriods&quot;: 2,
     &quot;MetricName&quot;: &quot;cdn-connectivity&quot;,
     &quot;Namespace&quot;: &quot;Bookstore&quot;,
     &quot;Period&quot;: 60,
     &quot;Statistic&quot;: &quot;Average&quot;,
     &quot;Threshold&quot;: 1.0
 }'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;performing-a-db-failure-simulation-test&quot;&gt;Performing a DB Failure Simulation Test&lt;/h3&gt;

&lt;p&gt;To meet the &lt;strong&gt;Stage 3&lt;/strong&gt; criteria of performing “frequent, semi-automated tests” we can use Chaos Engineering tools like Gremlin to easily schedule automated attacks on relevant services and machines.  This allows your team to properly prepare for, evaluate, and respond to the outcome of these tests.&lt;/p&gt;

&lt;p&gt;For the &lt;strong&gt;Bookstore&lt;/strong&gt; example application we’re simulating a failure of the database by preventing the &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; environment from establishing a database connection.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Schedule a Gremlin &lt;code class=&quot;highlighter-rouge&quot;&gt;Blackhole&lt;/code&gt; Attack targeting the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue&lt;/code&gt; environment that specifies the primary database endpoint (&lt;code class=&quot;highlighter-rouge&quot;&gt;db.bookstore.pingpublications.com&lt;/code&gt;) as a &lt;code class=&quot;highlighter-rouge&quot;&gt;Hostname&lt;/code&gt;.  Check out the &lt;a href=&quot;https://app.gremlin.com/api&quot;&gt;Gremlin API&lt;/a&gt; or &lt;a href=&quot;https://help.gremlin.com/attacks/&quot;&gt;documentation&lt;/a&gt; for more details on creating Gremlin Attacks.&lt;/p&gt;

    &lt;p&gt;This will automatically simulate a failure of the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue&lt;/code&gt; instance’s ability to connect to the primary database endpoint, which causes the custom &lt;code class=&quot;highlighter-rouge&quot;&gt;db-connectivity&lt;/code&gt; metrics to fail and trigger the subsequent Amazon Cloudwatch alarm.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Check the status of the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db-connectivity&lt;/code&gt; service to confirm that the health check is now failing.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl status bookstore-db-connectivity.service
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;...]
 Nov 25 21:18:02 bookstore-api-blue db-connectivity.sh[785]: Connection to db.bookstore.pingpublications.com 5432 port &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;tcp/postgresql] succeeded!
 Nov 25 21:18:18 bookstore-api-blue db-connectivity.sh[785]: Connection to db.bookstore.pingpublications.com 5432 port &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;tcp/postgresql] failed!
 Nov 25 21:18:49 bookstore-api-blue db-connectivity.sh[785]: Connection to db.bookstore.pingpublications.com 5432 port &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;tcp/postgresql] failed!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;aws cloudwatch get-metric-statistics&lt;/code&gt; to check the &lt;code class=&quot;highlighter-rouge&quot;&gt;db-connectivity&lt;/code&gt; metric around this time to see the actual metric values reported in AWS.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws cloudwatch get-metric-statistics &lt;span class=&quot;nt&quot;&gt;--metric-name&lt;/span&gt; db-connectivity &lt;span class=&quot;nt&quot;&gt;--start-time&lt;/span&gt; 2018-11-25T21:17:00Z &lt;span class=&quot;nt&quot;&gt;--end-time&lt;/span&gt; 2018-11-25T21:24:00Z &lt;span class=&quot;nt&quot;&gt;--period&lt;/span&gt; 60 &lt;span class=&quot;nt&quot;&gt;--namespace&lt;/span&gt; Bookstore &lt;span class=&quot;nt&quot;&gt;--statistics&lt;/span&gt; Average &lt;span class=&quot;nt&quot;&gt;--dimensions&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;Name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Host,Value&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;bookstore-api-blue &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Datapoints[*].{Timestamp:Timestamp,Average:Average}&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-25T21:20:00Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Average&quot;&lt;/span&gt;: 0.0
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-25T21:18:00Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Average&quot;&lt;/span&gt;: 0.25
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-25T21:19:00Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Average&quot;&lt;/span&gt;: 0.0
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-25T21:23:00Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Average&quot;&lt;/span&gt;: 1.0
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-25T21:17:00Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Average&quot;&lt;/span&gt;: 1.0
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-25T21:22:00Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Average&quot;&lt;/span&gt;: 0.8
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-25T21:21:00Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Average&quot;&lt;/span&gt;: 0.0
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Here we see the &lt;code class=&quot;highlighter-rouge&quot;&gt;db-connectivity&lt;/code&gt; health is acceptable (&lt;code class=&quot;highlighter-rouge&quot;&gt;1.0&lt;/code&gt;) until it starts to drop around &lt;code class=&quot;highlighter-rouge&quot;&gt;21:18:00&lt;/code&gt;, then remains at &lt;code class=&quot;highlighter-rouge&quot;&gt;0.0&lt;/code&gt; for a few minutes before returning to healthy status.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This metric failure triggered the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue-db-connectivity-failed&lt;/code&gt; Amazon Cloudwatch alarm that we also created.  This can be confirmed by checking the alarm history status around that same time period.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws cloudwatch describe-alarm-history &lt;span class=&quot;nt&quot;&gt;--alarm-name&lt;/span&gt; bookstore-api-blue-db-connectivity-failed &lt;span class=&quot;nt&quot;&gt;--history-item-type&lt;/span&gt; StateUpdate &lt;span class=&quot;nt&quot;&gt;--start-date&lt;/span&gt; 2018-11-25T21:17:00Z &lt;span class=&quot;nt&quot;&gt;--end-date&lt;/span&gt; 2018-11-25T21:28:00Z &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;AlarmHistoryItems[*].{Timestamp:Timestamp,Summary:HistorySummary}&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-25T21:24:09.620Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Summary&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Alarm updated from ALARM to OK&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;Timestamp&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;2018-11-25T21:20:09.620Z&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Summary&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Alarm updated from OK to ALARM&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Here we see that the alarm was triggered at &lt;code class=&quot;highlighter-rouge&quot;&gt;21:20:09.620&lt;/code&gt; and remained for four minutes before returning to &lt;code class=&quot;highlighter-rouge&quot;&gt;OK&lt;/code&gt; status.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p class=&quot;notice--tip&quot;&gt;Since an &lt;em&gt;actual&lt;/em&gt; database failure is handled by the Multi-AZ Amazon RDS configuration created in &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-2#database-failure-test&quot;&gt;Stage 2 - Database Failure Test&lt;/a&gt;, this automated critical dependency failure test doesn’t currently trigger any actual failover actions.  However, alarms are now configured to easily hook into disaster recovery actions as progress is made through the final &lt;strong&gt;Resiliency Stages&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;performing-a-cdn-failure-simulation-test&quot;&gt;Performing a CDN Failure Simulation Test&lt;/h3&gt;

&lt;p&gt;We use the same steps as above to perform a scheduled, automated Gremlin &lt;code class=&quot;highlighter-rouge&quot;&gt;Blackhole&lt;/code&gt; Attack to simulate failure of the CDN for our &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-blue&lt;/code&gt; environment.  Simply changing the &lt;code class=&quot;highlighter-rouge&quot;&gt;db-&lt;/code&gt; references to &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn-&lt;/code&gt;, and the relevant endpoints, will do the trick.  However, for brevity’s sake we won’t include the step-by-step instructions for doing so within this section.&lt;/p&gt;

&lt;h2 id=&quot;resiliency-stage-3-completion&quot;&gt;Resiliency Stage 3 Completion&lt;/h2&gt;

&lt;p&gt;Your team has been performing semi-automated tests at a regular cadence, has executed at least one resiliency experiment in production, and has disseminated all test results to the entire team.  With that, &lt;strong&gt;Resiliency Stage 3&lt;/strong&gt; is now complete.  Revenue loss and support costs should finally be dramatically dropping as fewer failures occur, and those that do happen last for much shorter periods.  In &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-4&quot;&gt;Chaos Engineering Through Staged Resiliency - Stage 4&lt;/a&gt; we’ll explore automating resiliency testing in non-production, along with semi-automation of our disaster recovery failovers.&lt;/p&gt;</content><author><name>Gabe Wyatt</name></author><category term="resiliency" /><category term="staging" /></entry><entry><title type="html">Chaos Engineering Through Staged Resiliency - Stage 2</title><link href="http://localhost:4000/gremlin-blog-posts/chaos-engineering/chaos-engineering-through-staged-resiliency-stage-2/" rel="alternate" type="text/html" title="Chaos Engineering Through Staged Resiliency - Stage 2" /><published>2018-10-11T00:00:00-07:00</published><updated>2018-10-11T00:00:00-07:00</updated><id>http://localhost:4000/gremlin-blog-posts/chaos-engineering/chaos-engineering-through-staged-resiliency-stage-2</id><content type="html" xml:base="http://localhost:4000/gremlin-blog-posts/chaos-engineering/chaos-engineering-through-staged-resiliency-stage-2/">&lt;p&gt;In &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-1&quot;&gt;Chaos Engineering Through Staged Resiliency - Stage 1&lt;/a&gt; we explored how engineering teams at Walmart successfully identify and combat unexpected system failure using a series of “resiliency stages.”  We also demonstrated the process of going through &lt;strong&gt;Stage 1&lt;/strong&gt; for the &lt;strong&gt;Bookstore&lt;/strong&gt; API sample application.  We showed that completing &lt;strong&gt;Resiliency Stage 1&lt;/strong&gt; requires the definition of a disaster recovery failover playbook, dependency failover playbooks, team-wide agreement on said playbooks, and the execution of a manual failover exercise.&lt;/p&gt;

&lt;p&gt;In this second part we’ll dive into the components of &lt;strong&gt;Resiliency Stage 2&lt;/strong&gt;, which focuses on critical dependency failure testing in non-production environments.&lt;/p&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Creation and agreement on &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-1#prerequisites&quot;&gt;Disaster Recovery and Dependency Failover Playbooks&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Completion of &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-1&quot;&gt;Resiliency Stage 1&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;perform-critical-dependency-failure-tests-in-non-production&quot;&gt;Perform Critical Dependency Failure Tests in Non-Production&lt;/h2&gt;

&lt;p&gt;The most important aspect of &lt;strong&gt;Resiliency Stage 2&lt;/strong&gt; is testing the resilience of your systems when critical dependencies fail.  However, this early in the process the system can’t be expected to handle such failures in a production environment, so these tests should be performed in a non-production setting.&lt;/p&gt;

&lt;h3 id=&quot;manual-testing-is-okay&quot;&gt;Manual Testing Is Okay&lt;/h3&gt;

&lt;p&gt;Eventually, all experiments should be executed automatically, with little to no human intervention required.  However, during &lt;strong&gt;Resiliency Stage 2&lt;/strong&gt; the team should feel comfortable performing manual tests.  The goal here isn’t to test the &lt;em&gt;automation&lt;/em&gt; of the system, but rather to determine the outcome and system-wide impact whenever a critical dependency fails.&lt;/p&gt;

&lt;h2 id=&quot;publish-test-results&quot;&gt;Publish Test Results&lt;/h2&gt;

&lt;p&gt;After every critical dependency failure test is performed the results should be globally published to the entire team.  This allows every team member to closely scrutinize the outcome of a given test.  This encourages feedback and communication, which naturally provides insightful evaluation from the members that are best equipped to analyze the test results.&lt;/p&gt;

&lt;h2 id=&quot;resiliency-stage-2-implementation-example&quot;&gt;Resiliency Stage 2: Implementation Example&lt;/h2&gt;

&lt;p&gt;At present the &lt;strong&gt;Bookstore&lt;/strong&gt; sample app has no real concept of failover or resiliency – if the application or a critical dependency fails, the entire system fails along with it.&lt;/p&gt;

&lt;p class=&quot;text-center&quot;&gt;&lt;img alt=&quot;Bookstore App Architecture&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/chaos-engineering-through-staged-resiliency/stage-1/stage-1-architecture-09757f8939b8928a7e67174b1608765bba3acc766990411ec05e28a66d641805.png&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Bookstore App Architecture&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Completing &lt;strong&gt;Resiliency Stage 2&lt;/strong&gt; requires testing in a non-production environment, so this forces us to improve deployment and system resiliency by moving beyond a single point of failure.  Since we’re taking advantage of AWS we &lt;em&gt;could&lt;/em&gt; jump straight into implementing all the safety net features the AWS platform brings with it (e.g. auto scaling, elastic load balancing, traffic manipulation, etc).  However, going through each resiliency stage by meeting the minimal requirements provides more robust examples and lets us learn the intricacies of all components within the system.&lt;/p&gt;

&lt;p&gt;Therefore, before we go through this stage we’ll be modifying the &lt;strong&gt;Bookstore&lt;/strong&gt; architecture by adding a secondary staging environment.  In fact, this is a good opportunity to use a blue/green deployment strategy.  A blue/green configuration requires creating two parallel production environments.&lt;/p&gt;

&lt;p&gt;As an example scenario, the &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; environment is “active” and is handling production traffic.  Meanwhile, the other environment (&lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;) is used for staging application changes.  Once the &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; environment has been fully tested then traffic is routed to the &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; environment.  &lt;code class=&quot;highlighter-rouge&quot;&gt;Green&lt;/code&gt; now becomes the live production environment while &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; is unused and ready for the next staging phase.  If something goes wrong during deployment to &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;, traffic can be quickly routed back to the still-active &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; environment.&lt;/p&gt;

&lt;h3 id=&quot;adding-a-staging-app-environment&quot;&gt;Adding a Staging App Environment&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Create a new EC2 instance from the most recent launch template version.  Optionally, we can specify tags such as &lt;code class=&quot;highlighter-rouge&quot;&gt;Name&lt;/code&gt; to help differentiate between the two environments.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; aws ec2 run-instances &lt;span class=&quot;nt&quot;&gt;--launch-template&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;LaunchTemplateName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;bookstore-api-ec2 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--tag-specifications&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ResourceType=instance,Tags=[{Key=Name,Value=bookstore-api-green}]&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Verify the instance has been created by finding active instances generated from the same AMI.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws ec2 describe-instances &lt;span class=&quot;nt&quot;&gt;--filters&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Name=image-id,Values=ami-087ff330c90e99ac5,Name=instance-state-code,Values=16&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Reservations[*].Instances[*].[LaunchTime,PublicDnsName,PublicIpAddress]&quot;&lt;/span&gt;
 2018-11-09T04:37:32.000Z	ec2-54-188-3-235.us-west-2.compute.amazonaws.com	54.188.3.235
 2018-11-09T07:44:38.000Z	ec2-54-191-29-110.us-west-2.compute.amazonaws.com	54.191.29.110
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SSH into new environment.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ssh ec2-54-191-29-110.us-west-2.compute.amazonaws.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pull any new application changes and restart application.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/apps/bookstore_api &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; git pull &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl restart gunicorn
 From github.com:GabeStah/bookstore_api
     0f1b811..ee6f15c  master     -&amp;gt; origin/master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Verify that each instance environment is serving a different version of the application.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Here we check the app version for the current production endpoint.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl bookstore.pingpublications.com/version | jq
  &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;version&quot;&lt;/span&gt;: 3
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;And for the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-green&lt;/code&gt; environment.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl ec2-54-191-29-110.us-west-2.compute.amazonaws.com/version | jq
  &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;version&quot;&lt;/span&gt;: 4
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;configuring-multi-az-rds&quot;&gt;Configuring Multi-AZ RDS&lt;/h3&gt;

&lt;p&gt;The PostgreSQL database on Amazon RDS is not resilient – if the single instance fails, the entire application goes down.  RDS provides a &lt;a href=&quot;https://aws.amazon.com/rds/details/multi-az/&quot;&gt;Multi-AZ Deployment&lt;/a&gt; solution, which automatically creates a synchronous database replica on another Availability Zone.  In the event of a primary failure the secondary performs an automatic failover so there is little to no downtime.&lt;/p&gt;

&lt;p&gt;Modifying the existing &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db&lt;/code&gt; RDS instance so it uses a Multi-AZ Deployment is fairly simple.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Confirm the instance is not using Multi-AZ.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws rds describe-db-instances &lt;span class=&quot;nt&quot;&gt;--db-instance-identifier&lt;/span&gt; bookstore-db &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;DBInstances[*].[AvailabilityZone,MultiAZ]&quot;&lt;/span&gt;
 us-west-2a	False
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Modify the instance by passing the &lt;code class=&quot;highlighter-rouge&quot;&gt;multi-az&lt;/code&gt; flag.  In this case, we always want to apply changes immediately (rather than wait for the next scheduled maintenance window).&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; aws rds modify-db-instance &lt;span class=&quot;nt&quot;&gt;--db-instance-identifier&lt;/span&gt; bookstore-db &lt;span class=&quot;nt&quot;&gt;--multi-az&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--apply-immediately&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It may take a few minutes for the modification to take effect.  We can check the status within the &lt;code class=&quot;highlighter-rouge&quot;&gt;PendingModifiedValues&lt;/code&gt; key structure to confirm &lt;code class=&quot;highlighter-rouge&quot;&gt;MultiAZ&lt;/code&gt; is waiting to be modified.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws rds describe-db-instances &lt;span class=&quot;nt&quot;&gt;--db-instance-identifier&lt;/span&gt; bookstore-db &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;DBInstances[*].PendingModifiedValues.[MultiAZ]&quot;&lt;/span&gt;
 True
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;After about 10 minutes we can check the status once again to confirm that a Mutli-AZ Deployment is now active.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws rds describe-db-instances &lt;span class=&quot;nt&quot;&gt;--db-instance-identifier&lt;/span&gt; bookstore-db &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;DBInstances[*].[AvailabilityZone,MultiAZ]&quot;&lt;/span&gt;
 us-west-2a	True
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;amazon-s3-cross-region-replication&quot;&gt;Amazon S3 Cross-Region Replication&lt;/h3&gt;

&lt;p&gt;The last critical dependency for the &lt;strong&gt;Bookstore&lt;/strong&gt; app is the CDN, which relies on Amazon S3.  While Amazon S3 is a extremely resilient system and not prone to downtime, there is still some precedent for Amazon S3 failure.  Luckily, the service has the ability to automatically replicate objects between buckets within different AWS regions.&lt;/p&gt;

&lt;p&gt;To accomplish this we’re working around a quirk with Amazon S3 bucket naming and DNS routing.  Specifically, a CNAME DNS name must &lt;em&gt;exactly match&lt;/em&gt; a referenced Amazon S3 bucket name.  Therefore, we’ll continue using the &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com.s3.amazonaws.com&lt;/code&gt; Amazon S3 bucket (and Route53 CNAME record), but this bucket is now the &lt;em&gt;secondary&lt;/em&gt; CDN.  A new Amazon S3 bucket named &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn-primary.bookstore.pingpublications.com&lt;/code&gt; is now the &lt;em&gt;primary&lt;/em&gt; CDN bucket.&lt;/p&gt;

&lt;p&gt;We then create a CloudFront endpoint that points to the &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn-primary&lt;/code&gt; bucket, but uses the DNS CNAME &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com&lt;/code&gt;.  From there, Amazon Route53 failover properly handles requests based on whichever Amazon S3 bucket is available.  This automates the CDN failover process.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Start by creating an Amazon CloudFront Distribution.  The fields we need to set are as follows.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Origin Domain Name&lt;/strong&gt;: This must be set the &lt;em&gt;primary&lt;/em&gt; Amazon S3 bucket (&lt;code class=&quot;highlighter-rouge&quot;&gt;cdn-primary.bookstore.pingpublications.com.s3-us-west-2.amazonaws.com&lt;/code&gt;).&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Alternate Domain Names (CNAMEs)&lt;/strong&gt;: This should point to the root CDN endpoint (&lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com&lt;/code&gt;).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create a Amazon Route53 Health Check to check the health of the &lt;em&gt;primary&lt;/em&gt; Amazon S3 bucket, which is behind the CloudFront endpoint created above.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 create-health-check &lt;span class=&quot;nt&quot;&gt;--caller-reference&lt;/span&gt; BookstoreCloudfront &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--health-check-config&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;FullyQualifiedDomainName&quot;: &quot;dqno94z16p2mg.cloudfront.net&quot;,
     &quot;ResourcePath&quot;: &quot;/static/status.json&quot;,
     &quot;Type&quot;: &quot;HTTP&quot;
 }'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;{Id: HealthCheck.Id}&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;352ef27f-213e-4dae-983e-62fd048ea7be&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;TIP&lt;/strong&gt;: We’ve added a &lt;code class=&quot;highlighter-rouge&quot;&gt;status.json&lt;/code&gt; file to our static asset collection, which we’ll use to confirm the online status of both CDN buckets, as well as determine which bucket is currently serving our content.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create another Amazon Route53 Health Check to check the status of the &lt;em&gt;secondary&lt;/em&gt; Amazon S3 bucket (&lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com.s3.amazonaws.com&lt;/code&gt;).&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 create-health-check &lt;span class=&quot;nt&quot;&gt;--caller-reference&lt;/span&gt; BookstoreS3 &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--health-check-config&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;FullyQualifiedDomainName&quot;: &quot;cdn.bookstore.pingpublications.com.s3.amazonaws.com&quot;,
     &quot;ResourcePath&quot;: &quot;/static/status.json&quot;,
     &quot;Type&quot;: &quot;HTTP&quot;
 }'&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;{Id: HealthCheck.Id}&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;e7fce91f-c82a-460f-b247-58c35790e39d&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create a third Amazon Route53 Health Check that combines the two previous health checks.  This combined health check is monitored by Amazon Route53 and automatically triggers failover from the primary to secondary CDN when the check fails.  We need to pass the two health check &lt;code class=&quot;highlighter-rouge&quot;&gt;Ids&lt;/code&gt; created above into this combined health check configuration.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 create-health-check &lt;span class=&quot;nt&quot;&gt;--caller-reference&lt;/span&gt; BookstoreCDN &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--health-check-config&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
     &quot;HealthThreshold&quot;: 2,
     &quot;Type&quot;: &quot;CALCULATED&quot;,
     &quot;ChildHealthChecks&quot;: [
         &quot;e7fce91f-c82a-460f-b247-58c35790e39d&quot;,
         &quot;352ef27f-213e-4dae-983e-62fd048ea7be&quot;
     ]
 }'&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheck&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckConfig&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&quot;HealthThreshold&quot;&lt;/span&gt;: 2,
             &lt;span class=&quot;s2&quot;&gt;&quot;Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;CALCULATED&quot;&lt;/span&gt;,
             &lt;span class=&quot;s2&quot;&gt;&quot;ChildHealthChecks&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&quot;352ef27f-213e-4dae-983e-62fd048ea7be&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;e7fce91f-c82a-460f-b247-58c35790e39d&quot;&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,
             &lt;span class=&quot;s2&quot;&gt;&quot;Inverted&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;CallerReference&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;BookstoreCDN&quot;&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckVersion&quot;&lt;/span&gt;: 1,
         &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;99d5b3a0-7709-4553-934f-d0ac7bcd2eb3&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;,
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Finally, verify all CDN endpoints behave correctly and point to the proper Amazon S3 bucket.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Start by checking the primary Amazon S3 bucket.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl http://cdn-primary.bookstore.pingpublications.com.s3-us-west-2.amazonaws.com/static/status.json
  &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;online&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;cdn&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;primary&quot;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The CloudFront endpoint routes to the primary bucket above.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl http://dqno94z16p2mg.cloudfront.net/static/status.json
  &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;online&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;cdn&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;primary&quot;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The last part of the chain is the primary CDN endpoint, which routes to the CloudFront endpoint, and then onto the primary Amazon S3 bucket itself.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl http://cdn.bookstore.pingpublications.com/static/status.json
  &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;online&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;cdn&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;primary&quot;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Finally, the secondary Amazon S3 bucket is properly retrieving the secondary static content.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl http://cdn.bookstore.pingpublications.com.s3.amazonaws.com/static/status.json
  &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;s2&quot;&gt;&quot;online&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
      &lt;span class=&quot;s2&quot;&gt;&quot;cdn&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;secondary&quot;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The app is now ready for failure testing.  Here is the updated diagram showing the &lt;strong&gt;Bookstore&lt;/strong&gt; app architecture for &lt;strong&gt;Resiliency Stage 2&lt;/strong&gt;.&lt;/p&gt;

&lt;p class=&quot;text-center&quot;&gt;&lt;img alt=&quot;Stage 2 - Architecture&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/chaos-engineering-through-staged-resiliency/stage-2/stage-2-architecture-eeb5feeb193e86e0a7004de150b11cf20e08a802a02a5b1cb1e6172a4b76e5e3.png&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Bookstore App Architecture&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;database-failure-test&quot;&gt;Database Failure Test&lt;/h3&gt;

&lt;p&gt;With Multi-AZ configured on the Amazon RDS instance we are now ready to perform a failover test for this critical dependency.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Confirm the status and current Availability Zone of the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db&lt;/code&gt; instance with the &lt;code class=&quot;highlighter-rouge&quot;&gt;describe-db-instances&lt;/code&gt; CLI command.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws rds describe-db-instances &lt;span class=&quot;nt&quot;&gt;--db-instance-identifier&lt;/span&gt; bookstore-db &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;DBInstances[*].{Id:DBInstanceIdentifier, AZ:AvailabilityZone, SecondaryAZ:SecondaryAvailabilityZone, Endpoint:Endpoint.Address, Status:DBInstanceStatus}&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;SecondaryAZ&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;us-west-2b&quot;&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;Status&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;available&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;AZ&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;us-west-2a&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-db&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Endpoint&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-db.cvajeopcjvda.us-west-2.rds.amazonaws.com&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Perform a manual reboot via &lt;code class=&quot;highlighter-rouge&quot;&gt;reboot-db-instance&lt;/code&gt;.  We’re also &lt;strong&gt;forcing&lt;/strong&gt; a failover with the &lt;code class=&quot;highlighter-rouge&quot;&gt;--force-failover&lt;/code&gt; flag.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws rds reboot-db-instance &lt;span class=&quot;nt&quot;&gt;--db-instance-identifier&lt;/span&gt; bookstore-db &lt;span class=&quot;nt&quot;&gt;--force-failover&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;DBInstance.{Id:DBInstanceIdentifier, AZ:AvailabilityZone, SecondaryAZ:SecondaryAvailabilityZone, Endpoint:Endpoint.Address, Status:DBInstanceStatus}&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;SecondaryAZ&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;us-west-2b&quot;&lt;/span&gt;, 
     &lt;span class=&quot;s2&quot;&gt;&quot;Status&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;rebooting&quot;&lt;/span&gt;, 
     &lt;span class=&quot;s2&quot;&gt;&quot;AZ&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;us-west-2a&quot;&lt;/span&gt;, 
     &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-db&quot;&lt;/span&gt;, 
     &lt;span class=&quot;s2&quot;&gt;&quot;Endpoint&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-db.cvajeopcjvda.us-west-2.rds.amazonaws.com&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Even though the primary instance is currently &lt;code class=&quot;highlighter-rouge&quot;&gt;Status: rebooting&lt;/code&gt;, both the production and secondary &lt;strong&gt;Bookstore&lt;/strong&gt; environments are able to connect to &lt;code class=&quot;highlighter-rouge&quot;&gt;db.bookstore.pingpublications.com&lt;/code&gt;, which is pointed to the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db.cvajeopcjvda.us-west-2.rds.amazonaws.com&lt;/code&gt; endpoint.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl bookstore.pingpublications.com/books/ | jq
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://bookstore.pingpublications.com/books/1/&quot;&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;authors&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://bookstore.pingpublications.com/authors/1/&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;birth_date&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1947-09-21&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;first_name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Stephen&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;last_name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;King&quot;&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;publication_date&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1978-09-01&quot;&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;title&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;The Stand&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl ec2-54-191-29-110.us-west-2.compute.amazonaws.com/books/ | jq
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://ec2-54-191-29-110.us-west-2.compute.amazonaws.com/books/1/&quot;&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;authors&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://ec2-54-191-29-110.us-west-2.compute.amazonaws.com/authors/1/&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;birth_date&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1947-09-21&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;first_name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Stephen&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;last_name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;King&quot;&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;publication_date&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1978-09-01&quot;&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;title&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;The Stand&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Amazon RDS Multi-AZ &lt;a href=&quot;https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RebootInstance.html&quot;&gt;automatically&lt;/a&gt; switches to the secondary replica on the other Availability Zone and reroutes the endpoint for us.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Once the reboot completes, query the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db&lt;/code&gt; instance to confirm that it has swapped the active instance to the other Availability Zone.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws rds describe-db-instances &lt;span class=&quot;nt&quot;&gt;--db-instance-identifier&lt;/span&gt; bookstore-db &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;DBInstances[*].{Id:DBInstanceIdentifier, AZ:AvailabilityZone, SecondaryAZ:SecondaryAvailabilityZone, Endpoint:Endpoint.Address, Status:DBInstanceStatus}&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;SecondaryAZ&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;us-west-2a&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Status&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;available&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;AZ&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;us-west-2b&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-db&quot;&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Endpoint&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;bookstore-db.cvajeopcjvda.us-west-2.rds.amazonaws.com&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Manually confirm the &lt;strong&gt;Bookstore&lt;/strong&gt; API remains connected to the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db&lt;/code&gt; instance replica.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl bookstore.pingpublications.com/books/ | jq
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://bookstore.pingpublications.com/books/1/&quot;&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;authors&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://bookstore.pingpublications.com/authors/1/&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;birth_date&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1947-09-21&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;first_name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Stephen&quot;&lt;/span&gt;,
                 &lt;span class=&quot;s2&quot;&gt;&quot;last_name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;King&quot;&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;publication_date&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1978-09-01&quot;&lt;/span&gt;,
         &lt;span class=&quot;s2&quot;&gt;&quot;title&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;The Stand&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;cdn-failure-test&quot;&gt;CDN Failure Test&lt;/h3&gt;

&lt;p&gt;This test ensures that the primary CDN endpoint (&lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com&lt;/code&gt;) performs an automatic failover to the secondary Amazon S3 bucket when the Route53 Health Check fails.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Retrieve appropriate Health Check &lt;code class=&quot;highlighter-rouge&quot;&gt;Ids&lt;/code&gt;.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 list-health-checks &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;HealthChecks&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckConfig&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&quot;HealthThreshold&quot;&lt;/span&gt;: 2, 
                 &lt;span class=&quot;s2&quot;&gt;&quot;Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;CALCULATED&quot;&lt;/span&gt;, 
                 &lt;span class=&quot;s2&quot;&gt;&quot;ChildHealthChecks&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
                     &lt;span class=&quot;s2&quot;&gt;&quot;57a1606e-df1e-43d0-b6d5-e04bf3d789ff&quot;&lt;/span&gt;, 
                     &lt;span class=&quot;s2&quot;&gt;&quot;e4a34329-26c3-4dbe-bec7-4afba94bd487&quot;&lt;/span&gt;
                 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;, 
                 &lt;span class=&quot;s2&quot;&gt;&quot;Inverted&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckVersion&quot;&lt;/span&gt;: 2, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1b01881d-a658-4d8e-86c9-8d5329d0bfcc&quot;&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Invert the Health Check, so that a normally healthy value is now considered unhealthy.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 update-health-check &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--health-check-id&lt;/span&gt; 1b01881d-a658-4d8e-86c9-8d5329d0bfcc &lt;span class=&quot;nt&quot;&gt;--inverted&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheck&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckConfig&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&quot;HealthThreshold&quot;&lt;/span&gt;: 2, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;CALCULATED&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;ChildHealthChecks&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&quot;57a1606e-df1e-43d0-b6d5-e04bf3d789ff&quot;&lt;/span&gt;, 
                 &lt;span class=&quot;s2&quot;&gt;&quot;e4a34329-26c3-4dbe-bec7-4afba94bd487&quot;&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Inverted&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckVersion&quot;&lt;/span&gt;: 3, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1b01881d-a658-4d8e-86c9-8d5329d0bfcc&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;After a moment for the Health Check status to update, check the primary CDN endpoint to ensure that it has automatically failed over to the secondary CDN Amazon S3 bucket.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl http://cdn.bookstore.pingpublications.com/static/status.json
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;online&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
     &lt;span class=&quot;s2&quot;&gt;&quot;cdn&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;secondary&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Revert the previous Health Check inversion.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws route53 update-health-check &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--health-check-id&lt;/span&gt; 1b01881d-a658-4d8e-86c9-8d5329d0bfcc &lt;span class=&quot;nt&quot;&gt;--no-inverted&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheck&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckConfig&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&quot;HealthThreshold&quot;&lt;/span&gt;: 2, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Type&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;CALCULATED&quot;&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;ChildHealthChecks&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&quot;57a1606e-df1e-43d0-b6d5-e04bf3d789ff&quot;&lt;/span&gt;, 
                 &lt;span class=&quot;s2&quot;&gt;&quot;e4a34329-26c3-4dbe-bec7-4afba94bd487&quot;&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;, 
             &lt;span class=&quot;s2&quot;&gt;&quot;Inverted&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
         &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;, 
         &lt;span class=&quot;s2&quot;&gt;&quot;HealthCheckVersion&quot;&lt;/span&gt;: 4, 
         &lt;span class=&quot;s2&quot;&gt;&quot;Id&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1b01881d-a658-4d8e-86c9-8d5329d0bfcc&quot;&lt;/span&gt;
     &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Verify that the primary CDN endpoint points back to the primary Amazon S3 bucket.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl http://cdn.bookstore.pingpublications.com/static/status.json
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s2&quot;&gt;&quot;online&quot;&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;,
     &lt;span class=&quot;s2&quot;&gt;&quot;cdn&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;primary&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;publish-test-results-1&quot;&gt;Publish Test Results&lt;/h3&gt;

&lt;p&gt;Now that both critical dependencies have been tested we’ll publish the results to the entire team, so everyone can keep tabs on the resiliency progress of the project.&lt;/p&gt;

&lt;p&gt;In this case, both the &lt;a href=&quot;#database-failure-test&quot;&gt;Database Failure Test&lt;/a&gt; and &lt;a href=&quot;#cdn-failure-test&quot;&gt;CDN Failure Test&lt;/a&gt; were performed manually within less than 15 minutes.  Therefore, we can safely update some of the playbook information created during the prerequisite phase of &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-1&quot;&gt;Resiliency Stage 1&lt;/a&gt; and reduce the critical dependency RTO/RPO targets significantly.  Even a conservative estimate of &lt;code class=&quot;highlighter-rouge&quot;&gt;1 hour&lt;/code&gt; is a massive improvement to resiliency and reduction to potential support costs, and we’re only through the second Stage!&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Dependency&lt;/th&gt;
      &lt;th&gt;Criticality Period&lt;/th&gt;
      &lt;th&gt;Manual Workaround&lt;/th&gt;
      &lt;th&gt;RTO&lt;/th&gt;
      &lt;th&gt;RPO&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Database&lt;/td&gt;
      &lt;td&gt;Always&lt;/td&gt;
      &lt;td&gt;Manual verification of Amazon RDS Multi-AZ secondary instance failover.&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CDN&lt;/td&gt;
      &lt;td&gt;Always&lt;/td&gt;
      &lt;td&gt;Manual verification of secondary Amazon S3 bucket failover DNS routing.&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;resiliency-stage-2-completion&quot;&gt;Resiliency Stage 2 Completion&lt;/h2&gt;

&lt;p&gt;Once all critical dependencies have been failure tested and those test results have been disseminated throughout the team then &lt;strong&gt;Resiliency Stage 2&lt;/strong&gt; is complete!  Your system should now have well-defined recovery playbooks and been manually tested for both failover and critical dependency failures.  In &lt;a href=&quot;https://www.gremlin.com/blog/chaos-engineering-through-staged-resiliency-stage-3&quot;&gt;Chaos Engineering Through Staged Resiliency - Stage 3&lt;/a&gt; we’ll look at the transition into automating some of these tests and performing them at regular intervals.&lt;/p&gt;</content><author><name>Gabe Wyatt</name></author><category term="resiliency" /><category term="staging" /></entry><entry><title type="html">Chaos Engineering Through Staged Resiliency - Stage 1</title><link href="http://localhost:4000/gremlin-blog-posts/chaos-engineering/chaos-engineering-through-staged-resiliency-stage-1/" rel="alternate" type="text/html" title="Chaos Engineering Through Staged Resiliency - Stage 1" /><published>2018-10-11T00:00:00-07:00</published><updated>2018-10-11T00:00:00-07:00</updated><id>http://localhost:4000/gremlin-blog-posts/chaos-engineering/chaos-engineering-through-staged-resiliency-stage-1</id><content type="html" xml:base="http://localhost:4000/gremlin-blog-posts/chaos-engineering/chaos-engineering-through-staged-resiliency-stage-1/">&lt;p&gt;In spite of what the name may suggest, Chaos Engineering is a &lt;em&gt;disciplined&lt;/em&gt; approach of identifying potential failures before they become outages.  Ultimately, the goal of Chaos Engineering is to create more stable and &lt;strong&gt;resilient&lt;/strong&gt; systems.  There is some disagreement in the community about proper terminology, but regardless of which side of the &lt;a href=&quot;https://medium.com/@jpaulreed/chaos-engineered-or-otherwise-is-not-enough-ad5792309ecf&quot;&gt;Chaos Engineering&lt;/a&gt; vs &lt;a href=&quot;https://www.linkedin.com/pulse/would-chaos-any-othername-casey-rosenthal/&quot;&gt;Resilience Engineering&lt;/a&gt; debate you come down on, most engineers probably agree that proper implementation is more important than naming semantics.&lt;/p&gt;

&lt;p&gt;Creating resilient software is a fundamental necessity within modern cloud applications and architectures.  As systems become more distributed the potential for unplanned outages and unexpected failure significantly increases.  Thankfully, Chaos and Resilience Engineering techniques are quickly gaining traction within the community.  &lt;a href=&quot;https://coggle.it/diagram/WiKceGDAwgABrmyv/t/chaos-engineering-companies%2C-people%2C-tools-practices&quot;&gt;Many organizations&lt;/a&gt; – both big and small – have embraced Chaos Engineering over the last few years.  In his fascinating &lt;a href=&quot;https://chaosconf.splashthat.com/&quot;&gt;ChaosConf 2018&lt;/a&gt; talk titled &lt;a href=&quot;https://www.youtube.com/watch?v=4Gy_5EQMrB4&quot;&gt;&lt;em&gt;Practicing Chaos Engineering at Walmart&lt;/em&gt;&lt;/a&gt;, Walmart’s Director of Engineering Vilas Veeraraghavan outlines how he and the hundreds of engineering teams at Walmart have implemented Resilience Engineering.  By creating a robust series of “levels” or “stages” that each engineering team can work through, Walmart is able to progressively improve system resiliency while dramatically reducing support costs.&lt;/p&gt;

&lt;p&gt;This blog series expands on Vilas’ and Walmart’s techniques by diving deep into the five &lt;strong&gt;Stages of Resiliency&lt;/strong&gt;.  Each post examines the necessary components of a stage, describes how those components are evaluated and assembled, and outlines the step-by-step process necessary to move from one stage to the next.&lt;/p&gt;

&lt;p&gt;This series also digs into the specific implementation of each stage by progressing through the entire process with a real-world, fully-functional API application hosted on AWS.  We’ll go through everything from defining and executing disaster recovery playbook scenarios to improving system architecture and reducing RTO, RPO, and applicable support costs for this example app.&lt;/p&gt;

&lt;p&gt;With a bit of adjustment for your own organizational needs, you and your team can implement similar practices to quickly add Chaos Engineering to your own systems with relative ease.  After climbing through all five stages your system and its deployment will be almost entirely automated and will feature significant resiliency testing and robust disaster recovery failover.&lt;/p&gt;

&lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: The remainder of this article will use the term &lt;code class=&quot;highlighter-rouge&quot;&gt;team&lt;/code&gt; to indicate a singular group that is responsible for an application that is progressing through the resiliency stages.&lt;/p&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;

&lt;p&gt;Before you can begin moving through the resiliency stages there are a few prerequisite steps you’ll need to complete.  Most of these requirements are standard fare for a well-designed system, but ensuring each and every unique application team is fully prepared for the unknown is paramount to developing resilient systems.&lt;/p&gt;

&lt;h3 id=&quot;1-establish-high-observability&quot;&gt;1. Establish High Observability&lt;/h3&gt;

&lt;p&gt;Microservice and clustered architectures favor the scalability and cost-efficiency of distributed computing, but also require a deep understanding of system behavior across a large pool of services and machines.  Robust observability is a necessity for most modern software, which tend to be comprised of these complex distributed systems.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: The act of collecting, processing, aggregating, and displaying quantitative data about a system.  These data may be anything from query counts/types and error counts/types to processing times and server lifetimes.  Monitoring is a smaller subset of overall measure of observability.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Observability&lt;/strong&gt;: A measure of the ability to accurately infer what is happening internally within a system based solely on external information.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Continuous monitoring is critical to catch unexpected behavior that is difficult to reproduce, but at least historically, monitoring has largely focused on measuring “known unknowns.”  By contrast, a highly-distributed system often requires tracking down, understanding, and preparing for a multitude of “unknown unknowns” – obscure issues that have never happened before, and may never happen again.  A properly &lt;em&gt;observable&lt;/em&gt; system is one that allows your team to answer new questions about the internals of the system &lt;em&gt;without&lt;/em&gt; the need to deploy a new build.  This kind of observability is often referred to as “blackbox monitoring,” as it allows your team to draw conclusions about unknowable events without using the internals of the system.&lt;/p&gt;

&lt;p&gt;Most importantly, high observability is critically important when implementing Chaos Engineering techniques.  As &lt;a href=&quot;https://twitter.com/mipsytipsy&quot;&gt;Charity Majors&lt;/a&gt;, CEO of &lt;a href=&quot;https://www.honeycomb.io/&quot;&gt;Honeycomb&lt;/a&gt;, puts it, “Without observability, you don’t have ‘chaos engineering’.  You just have chaos.”&lt;/p&gt;

&lt;h3 id=&quot;2-define-the-critical-dependencies&quot;&gt;2. Define the Critical Dependencies&lt;/h3&gt;

&lt;p&gt;Start by documenting every application dependency that is &lt;em&gt;required&lt;/em&gt; for the application to function at all.  This type of dependency is referred to as a &lt;strong&gt;critical dependency&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;3-define-the-non-critical-dependencies&quot;&gt;3. Define the Non-Critical Dependencies&lt;/h3&gt;

&lt;p&gt;Once all critical dependencies are identified then all remaining dependencies should be &lt;strong&gt;non-critical dependencies&lt;/strong&gt;.  If the core application can still function – even in a degraded state – when a dependency is missing, then that dependency is considered non-critical.&lt;/p&gt;

&lt;h3 id=&quot;4-create-a-disaster-recovery-failover-playbook&quot;&gt;4. Create a Disaster Recovery Failover Playbook&lt;/h3&gt;

&lt;p&gt;Your team should create a disaster recovery plan specific to &lt;strong&gt;failover&lt;/strong&gt;.  A &lt;strong&gt;disaster recovery failover playbook&lt;/strong&gt; should include the following information, at a minimum:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Contact information&lt;/strong&gt;: Explicitly document all relevant contact info for all team members.  Identifying priority team members based on seniority, role, expertise, and the like will prove beneficial for later steps.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Notification procedures&lt;/strong&gt;: This should answer all the “Who/What/When/Why/How” questions for notifying relevant team members.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Failover procedures&lt;/strong&gt;: Deliberate, step-by-step instructions for handling each potential &lt;strong&gt;failover scenario&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;TIP&lt;/strong&gt;: Not sure which failover scenarios to expect or plan for?  Unable to determine if a dependency is critical vs non-critical?  Consider running a GameDay to better prepare for and test specific scenarios in a controlled manner.  Check out &lt;a href=&quot;https://www.gremlin.com/community/tutorials/how-to-run-a-gameday/&quot;&gt;How to Run a GameDay&lt;/a&gt; for more info.&lt;/p&gt;

&lt;h3 id=&quot;5-create-a-critical-dependency-failover-playbook&quot;&gt;5. Create a Critical Dependency Failover Playbook&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;critical dependency failover playbook&lt;/strong&gt; is a subset of the disaster recovery failover playbook and it should detail the step-by-step procedures for handling the potential failover scenarios for each critical dependency.&lt;/p&gt;

&lt;h3 id=&quot;6-create-a-non-critical-dependency-failover-playbook&quot;&gt;6. Create a Non-Critical Dependency Failover Playbook&lt;/h3&gt;

&lt;p&gt;The final prerequisite is to determine how non-critical dependency failures will impact the system.  Your team may not &lt;em&gt;necessarily&lt;/em&gt; have failover procedures in place for non-critical dependencies, so this process can be as simple as testing and documenting what happens when each non-critical dependency is unavailable.  Be sure to gauge the &lt;strong&gt;severity&lt;/strong&gt; of the failure impact on the core application, which will provide the team with a better understanding of the system and its interactions (see &lt;a href=&quot;#recovery-objectives&quot;&gt;Recovery Objectives&lt;/a&gt;).&lt;/p&gt;

&lt;h4 id=&quot;recovery-objectives&quot;&gt;Recovery Objectives&lt;/h4&gt;

&lt;p&gt;Most disaster recovery playbooks define the goals and allotted impact of a given failure using two common terms: &lt;strong&gt;Recovery Time Objective&lt;/strong&gt; and &lt;strong&gt;Recovery Point Objective&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Recovery Time Objective (RTO)&lt;/strong&gt;: The maximum period of time in which the functionality of a failed service should be restored.  For example, if a service with an RTO of twelve hours experiences an outage at 5:00 PM then functionality should be restored to the service by 5:00 AM the next morning.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Recovery Point Objective (RPO)&lt;/strong&gt;: The maximum period of time during which data can be lost during a service failure.  For example, if a service with an RPO of two hours experiences an outage at 5:00 PM then &lt;em&gt;only&lt;/em&gt; data generated between 3:00 PM and 5:00 PM should be lost – all existing data prior to 3:00 PM should still be intact.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;text-center&quot;&gt;&lt;img alt=&quot;RTO &amp;amp; RPO Diagrammed - Courtesy of Wikipedia&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/chaos-engineering-through-staged-resiliency/stage-1/rto-rpo-example-wikipedia-2294d0f2a372d637a46304bc07fa57dd380b7cae63a3b16d1c79788378750ef7.png&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;RTO &amp;amp; RPO Diagrammed – Source: &lt;a href=&quot;https://en.wikipedia.org/wiki/File:RPO_RTO_example_converted.png&quot;&gt;Wikipedia&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;complete-and-publish-prerequisites&quot;&gt;Complete and Publish Prerequisites&lt;/h2&gt;

&lt;p&gt;Ensure that all &lt;a href=&quot;#prerequisites&quot;&gt;Prerequisites&lt;/a&gt; have been met.  All playbooks, dependency definitions, and other relevant documentation should be placed in a singular, globally accessible location so every single team member has immediate access to that information.  Maintaining a single repository for the information also maintains consistency across the team, so there’s never any confusion about the steps in a particular scenario or what is defined as a critical dependency.&lt;/p&gt;

&lt;h2 id=&quot;team-wide-agreement-on-playbooks&quot;&gt;Team-Wide Agreement on Playbooks&lt;/h2&gt;

&lt;p&gt;With unfettered access to all documentation, the next step is to ensure the entire team agrees with all documented information as its laid out.  If there is disagreement about the best way to approach a given failover scenario, or about the risk and potential impact of a non-critical dependency failure, this is the best time to suss out those differences of opinion and come to a unanimous “best” solution.  A healthy, active debate provides the team with a deeper understanding of the system and encourages the best ideas and techniques to bubble up to the surface.&lt;/p&gt;

&lt;p&gt;While the goal is agreement on the playbooks currently laid out, documentation can (and should) be updated in the future as experiments shed new light on the system.  The team should be encouraged and empowered to challenge the norms in order to create a system that is always adapting and evolving to be as resilient as possible.&lt;/p&gt;

&lt;h2 id=&quot;manually-execute-a-failover-exercise&quot;&gt;Manually Execute a Failover Exercise&lt;/h2&gt;

&lt;p&gt;The last step is to manually perform a failover exercise.  The goal of this exercise is to verify that the disaster recovery failover playbook works as expected.  Therefore, the step-by-step process defined in the playbook should be followed exactly as documented.&lt;/p&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: If an action or step is not &lt;em&gt;explicitly&lt;/em&gt; documented within a playbook then it should be ignored.  If the exercise fails or cannot be completed this likely indicates that the playbook needs to be updated.&lt;/p&gt;

&lt;h2 id=&quot;resiliency-stage-1-implementation-example&quot;&gt;Resiliency Stage 1: Implementation Example&lt;/h2&gt;

&lt;p&gt;Throughout this series, we’ll take a simple yet real-world application through the entire staging process to illustrate how a team might progress their application through all five resiliency stages.  While every application and system architecture is unique, this example illustrates the basics of implementing every step within a stage, to provide you with a jumping off point for staged resiliency within your own system.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/GabeStah/bookstore_api&quot;&gt;&lt;strong&gt;Bookstore&lt;/strong&gt; example application&lt;/a&gt; is a publicly accessible API for a virtual bookstore.  The API includes two primary endpoints: &lt;code class=&quot;highlighter-rouge&quot;&gt;/authors/&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;/books/&lt;/code&gt;, which can be used to add, update, or remove &lt;strong&gt;Authors&lt;/strong&gt; and &lt;strong&gt;Books&lt;/strong&gt;, respectively.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bookstore’s&lt;/strong&gt; architecture consists of three core components, all of which are housed within Amazon Web Services.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: The API is created with Django and the &lt;a href=&quot;https://www.django-rest-framework.org/&quot;&gt;Django REST Framework&lt;/a&gt; and is hosted on an Amazon EC2 instance running NGINX.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: A PostgreSQL database handles all data and uses Amazon RDS.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CDN&lt;/strong&gt;: All static content is collected in and served from an Amazon S3 bucket.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;text-center&quot;&gt;&lt;img alt=&quot;Stage 1 - Initial&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/chaos-engineering-through-staged-resiliency/stage-1/stage-1-architecture-09757f8939b8928a7e67174b1608765bba3acc766990411ec05e28a66d641805.png&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Initial System Architecture&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The web API is at the publicly accessible &lt;a href=&quot;http://bookstore.pingpublications.com&quot;&gt;http://bookstore.pingpublications.com&lt;/a&gt; endpoint.  The web API, database, and CDN endpoints are DNS-routed via Amazon Route53 to the underlying Amazon EC2, RDS, and Amazon S3 buckets, respectively.&lt;/p&gt;

&lt;p&gt;Here’s a simple request to the &lt;code class=&quot;highlighter-rouge&quot;&gt;/books/&lt;/code&gt; API endpoint.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl http://bookstore.pingpublications.com/books/ | jq
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://bookstore.pingpublications.com/books/1/&quot;&lt;/span&gt;,
    &lt;span class=&quot;s2&quot;&gt;&quot;authors&quot;&lt;/span&gt;: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s2&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://bookstore.pingpublications.com/authors/1/&quot;&lt;/span&gt;,
        &lt;span class=&quot;s2&quot;&gt;&quot;birth_date&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1947-09-21&quot;&lt;/span&gt;,
        &lt;span class=&quot;s2&quot;&gt;&quot;first_name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;Stephen&quot;&lt;/span&gt;,
        &lt;span class=&quot;s2&quot;&gt;&quot;last_name&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;King&quot;&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;,
    &lt;span class=&quot;s2&quot;&gt;&quot;publication_date&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;1978-09-01&quot;&lt;/span&gt;,
    &lt;span class=&quot;s2&quot;&gt;&quot;title&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;The Stand&quot;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: The initial design and architecture for the &lt;strong&gt;Bookstore&lt;/strong&gt; sample application is &lt;em&gt;intentionally&lt;/em&gt; less resilient than a full production-ready system.  This leaves room for improvement as progress is made through the resiliency stages throughout this series.&lt;/p&gt;

&lt;h3 id=&quot;prerequisites-1&quot;&gt;Prerequisites&lt;/h3&gt;

&lt;p&gt;We begin the example implementation by defining all prerequisites for the &lt;strong&gt;Bookstore&lt;/strong&gt; app.&lt;/p&gt;

&lt;h4 id=&quot;0-define-system-architecture&quot;&gt;0. Define System Architecture&lt;/h4&gt;

&lt;p&gt;It may be useful to take a moment to define the basic components of the system, which can then be referenced throughout your playbooks.  Below are the initial services for the &lt;strong&gt;Bookstore&lt;/strong&gt; app.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Service&lt;/th&gt;
      &lt;th&gt;Platform&lt;/th&gt;
      &lt;th&gt;Technologies&lt;/th&gt;
      &lt;th&gt;AZ&lt;/th&gt;
      &lt;th&gt;VPC&lt;/th&gt;
      &lt;th&gt;Subnet&lt;/th&gt;
      &lt;th&gt;Endpoint&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;API&lt;/td&gt;
      &lt;td&gt;Amazon EC2&lt;/td&gt;
      &lt;td&gt;Django, Nginx&lt;/td&gt;
      &lt;td&gt;us-west-2a&lt;/td&gt;
      &lt;td&gt;bookstore-vpc&lt;/td&gt;
      &lt;td&gt;bookstore-subnet-2a&lt;/td&gt;
      &lt;td&gt;bookstore.pingpublications.com&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Database&lt;/td&gt;
      &lt;td&gt;Amazon RDS&lt;/td&gt;
      &lt;td&gt;PostgreSQL 10.4&lt;/td&gt;
      &lt;td&gt;us-west-2a&lt;/td&gt;
      &lt;td&gt;bookstore-vpc&lt;/td&gt;
      &lt;td&gt;bookstore-subnet-2a&lt;/td&gt;
      &lt;td&gt;db.bookstore.pingpublications.com&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CDN&lt;/td&gt;
      &lt;td&gt;Amazon S3&lt;/td&gt;
      &lt;td&gt;Amazon S3&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
      &lt;td&gt;cdn.bookstore.pingpublications.com&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;1-define-the-critical-dependencies&quot;&gt;1. Define the Critical Dependencies&lt;/h4&gt;

&lt;p&gt;At this early stage of the application &lt;em&gt;all&lt;/em&gt; dependencies are critical.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Dependency&lt;/th&gt;
      &lt;th&gt;Criticality Period&lt;/th&gt;
      &lt;th&gt;Manual Workaround&lt;/th&gt;
      &lt;th&gt;RTO&lt;/th&gt;
      &lt;th&gt;RPO&lt;/th&gt;
      &lt;th&gt;Child Dependencies&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;API&lt;/td&gt;
      &lt;td&gt;Always&lt;/td&gt;
      &lt;td&gt;Manual Amazon EC2 Instance Restart&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;Database, CDN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Database&lt;/td&gt;
      &lt;td&gt;Always&lt;/td&gt;
      &lt;td&gt;Manual Amazon RDS Instance Restart&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;CDN&lt;/td&gt;
      &lt;td&gt;Always&lt;/td&gt;
      &lt;td&gt;Manual Amazon S3 Bucket Verification&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A &lt;strong&gt;criticality period&lt;/strong&gt; is useful for dependencies that are only considered “critical” during a specific period of time.  For example, a database backup service that runs at 2:00 AM PST every night may have a criticality period of &lt;code class=&quot;highlighter-rouge&quot;&gt;2:00 AM - 3:00 AM PST&lt;/code&gt;.  This is also a good time to evaluate initial acceptable RTO and RPO values.  These values will decrease over time as resiliency improves, but setting a baseline goal provides a target to work toward.&lt;/p&gt;

&lt;h4 id=&quot;2-define-the-non-critical-dependencies&quot;&gt;2. Define the Non-Critical Dependencies&lt;/h4&gt;

&lt;p&gt;The &lt;strong&gt;Bookstore&lt;/strong&gt; app is so simple that it doesn’t have any non-critical dependencies – if a service fails, the entire application fails with it.&lt;/p&gt;

&lt;h4 id=&quot;3-create-a-disaster-recovery-failover-playbook&quot;&gt;3. Create a Disaster Recovery Failover Playbook&lt;/h4&gt;

&lt;p&gt;The first part of a disaster recovery failover playbook should contain contact information for all relevant team members, including the services those members are related to and their availability.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Team Member&lt;/th&gt;
      &lt;th&gt;Position&lt;/th&gt;
      &lt;th&gt;Relevant Services&lt;/th&gt;
      &lt;th&gt;Email&lt;/th&gt;
      &lt;th&gt;Phone&lt;/th&gt;
      &lt;th&gt;Availability&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alice&lt;/td&gt;
      &lt;td&gt;Director of Technology&lt;/td&gt;
      &lt;td&gt;ALL&lt;/td&gt;
      &lt;td&gt;alice@example.com&lt;/td&gt;
      &lt;td&gt;555-555-5550&lt;/td&gt;
      &lt;td&gt;9 - 5, M - F&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;Lead Developer, Bookstore API&lt;/td&gt;
      &lt;td&gt;Bookstore API&lt;/td&gt;
      &lt;td&gt;bob@example.com&lt;/td&gt;
      &lt;td&gt;555-555-5551&lt;/td&gt;
      &lt;td&gt;9 - 5, M - F; 10 - 2, S &amp;amp; S&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Christina&lt;/td&gt;
      &lt;td&gt;Site Reliability Engineer&lt;/td&gt;
      &lt;td&gt;ALL&lt;/td&gt;
      &lt;td&gt;christina@example.com&lt;/td&gt;
      &lt;td&gt;555-555-5552&lt;/td&gt;
      &lt;td&gt;On-call&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To define the proper notification procedures it may help to add an organizational chart to the playbook.&lt;/p&gt;

&lt;p class=&quot;text-center&quot;&gt;&lt;img alt=&quot;Stage 1 - Org Chart&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/chaos-engineering-through-staged-resiliency/stage-1/stage-1-org-chart-ee71101491122a21a4ce29b88a4f97826e3805783c96e573e16ebe017595c2f6.png&quot; class=&quot;align-center&quot; /&gt;
&lt;em&gt;Organizational Chart&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This can be used in conjunction with the contact information table to determine which team members should be contacted – and in what priority – when a given service fails.&lt;/p&gt;

&lt;p&gt;The final part of the disaster recovery failover playbook is to explicitly document the step-by-step procedures for every failover scenario.  For the &lt;strong&gt;Bookstore&lt;/strong&gt; application, we’ll just provide a single failover scenario plan for when the database fails, but this can be expanded as necessary for all other failover scenarios.&lt;/p&gt;

&lt;h5 id=&quot;scenario-bookstore-api-failure&quot;&gt;Scenario: Bookstore API Failure&lt;/h5&gt;

&lt;p&gt;The current architecture of the &lt;strong&gt;Bookstore&lt;/strong&gt; app is limited to a manual &lt;em&gt;Backup &amp;amp; Restore&lt;/em&gt; disaster recovery strategy.&lt;/p&gt;

&lt;h6 id=&quot;disaster-recovery-leads&quot;&gt;Disaster Recovery Leads&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Primary: Bob, Lead Developer, Bookstore API&lt;/li&gt;
  &lt;li&gt;Secondary: Alice, Director of Technology&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;severity&quot;&gt;Severity&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Critical&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;PURPOSE&lt;/strong&gt;: The severity level of this particular failover.  Severity should be a general indicator of acceptable RTO/RPO metrics, as well as how critically dependent the service is.&lt;/p&gt;

&lt;h6 id=&quot;recovery-procedure-overview&quot;&gt;Recovery Procedure Overview&lt;/h6&gt;

&lt;ol&gt;
  &lt;li&gt;Manually verify if the API server has failed, or if the server is available but the Django API app failed.
    &lt;ul&gt;
      &lt;li&gt;If server failure: Manually restart API server.&lt;/li&gt;
      &lt;li&gt;If Django API app failure: Manually restart Django API app.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If neither restart solution works, propagate replacement server using prepared backup Amazon Machine Image (AMI).&lt;/li&gt;
  &lt;li&gt;Verify backup instance is functional.&lt;/li&gt;
  &lt;li&gt;Update DNS routing.&lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;basic-assumptions&quot;&gt;Basic Assumptions&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Amazon S3, Amazon RDS, Amazon Route 53, and Amazon EC2 are all online and functional.&lt;/li&gt;
  &lt;li&gt;Frequent AMI backups are generated for the application instance.&lt;/li&gt;
  &lt;li&gt;Application code can be restored from code repository with minimal manual effort.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;PURPOSE&lt;/strong&gt;: Indicates the basic assumptions that can be made during the recovery process.  Assumptions are typically factors outside of your control, such as third-party vendor availability.&lt;/p&gt;

&lt;h6 id=&quot;recovery-time-objective&quot;&gt;Recovery Time Objective&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;12 Hours&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-point-objective&quot;&gt;Recovery Point Objective&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;24 Hours&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-platform&quot;&gt;Recovery Platform&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Amazon EC2 &lt;code class=&quot;highlighter-rouge&quot;&gt;t2.micro&lt;/code&gt; instance on &lt;code class=&quot;highlighter-rouge&quot;&gt;us-west-2a&lt;/code&gt; Availability Zone with NGINX, Python, and Django &lt;strong&gt;Bookstore&lt;/strong&gt; application configured and installed from the latest release.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;PURPOSE&lt;/strong&gt;: Indicate the specific technologies, platforms, and services that are necessary to complete the recovery procedure.&lt;/p&gt;

&lt;h6 id=&quot;recovery-procedure&quot;&gt;Recovery Procedure&lt;/h6&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Manually verify the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api&lt;/code&gt; instance availability on Amazon EC2.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl http://bookstore.pingpublications.com
 curl: &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;7&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; Failed to connect to bookstore.pingpublications.com port 80: Connection refused
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;If the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api&lt;/code&gt; instance is active but &lt;strong&gt;Bookstore&lt;/strong&gt; Django application is failing then manually restart app from the terminal.&lt;/p&gt;

        &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl restart gunicorn
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If &lt;strong&gt;Bookstore&lt;/strong&gt; Django application remains offline then manually restart the instance and recheck application availability.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api&lt;/code&gt; EC2 instance has completely failed and must be replaced then propagate a new Amazon EC2 instance from the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-ec2-image&lt;/code&gt; AMI backup.&lt;/p&gt;

    &lt;p&gt;Use the pre-defined &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api-ec2&lt;/code&gt; launch template.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws ec2 run-instances &lt;span class=&quot;nt&quot;&gt;--launch-template&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;LaunchTemplateName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;bookstore-api-ec2
 532151327118   r-0e57eca4a2e78d479
 ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;Default values can be overridden as seen below.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; aws ec2 run-instances &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--image-id&lt;/span&gt; ami-087ff330c90e99ac5 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--count&lt;/span&gt; 1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--instance-type&lt;/span&gt; t2.micro &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--key-name&lt;/span&gt; gabe-ping-pub &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--security-group-ids&lt;/span&gt; sg-25268a50 sg-0f818c22884a88694 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
     &lt;span class=&quot;nt&quot;&gt;--subnet-id&lt;/span&gt; subnet-47ebaf0c
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Confirm the instance has been launched and retrieve the public DNS and IPv4 address.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;aws ec2 describe-instances &lt;span class=&quot;nt&quot;&gt;--filters&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Name=image-id,Values=ami-087ff330c90e99ac5,Name=instance-state-code,Values=16&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Reservations[*].Instances[*].[LaunchTime,PublicDnsName,PublicIpAddress]&quot;&lt;/span&gt;
 2018-11-09T04:37:32.000Z	ec2-54-188-3-235.us-west-2.compute.amazonaws.com	54.188.3.235
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: The &lt;code class=&quot;highlighter-rouge&quot;&gt;filters&lt;/code&gt; used in the command above searched for &lt;strong&gt;Running&lt;/strong&gt; instances based on the AMI &lt;code class=&quot;highlighter-rouge&quot;&gt;image-id&lt;/code&gt;.  If multiple instances match these filters then the &lt;code class=&quot;highlighter-rouge&quot;&gt;LaunchTime&lt;/code&gt; value retrieved from the query will help determine which instance is the latest launched.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SSH into the new &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api&lt;/code&gt; instance.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ssh ec2-54-188-3-235.us-west-2.compute.amazonaws.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Pull latest &lt;strong&gt;Bookstore&lt;/strong&gt; application code from the repository.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/apps/bookstore_api &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; git pull
 Already up to date.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Restart application via &lt;code class=&quot;highlighter-rouge&quot;&gt;gunicorn&lt;/code&gt;.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl restart gunicorn
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On a local machine verify backup instance is functional, the public IPv4 address is available, and the &lt;strong&gt;Bookstore&lt;/strong&gt; app is online.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl ec2-54-188-3-235.us-west-2.compute.amazonaws.com | jq
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;s2&quot;&gt;&quot;authors&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://ec2-54-188-3-235.us-west-2.compute.amazonaws.com/authors/&quot;&lt;/span&gt;,
   &lt;span class=&quot;s2&quot;&gt;&quot;books&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://ec2-54-188-3-235.us-west-2.compute.amazonaws.com/books/&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Update the Amazon Route 53 DNS &lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt; record to point to the new &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api&lt;/code&gt; EC2 instance IPv4 address.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Once DNS propagation completes verify that the API endpoint is functional.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl bookstore.pingpublications.com | jq
 &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;s2&quot;&gt;&quot;authors&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://bookstore.pingpublications.com/authors/&quot;&lt;/span&gt;,
   &lt;span class=&quot;s2&quot;&gt;&quot;books&quot;&lt;/span&gt;: &lt;span class=&quot;s2&quot;&gt;&quot;http://bookstore.pingpublications.com/books/&quot;&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;test-procedure&quot;&gt;Test Procedure&lt;/h6&gt;

&lt;ol&gt;
  &lt;li&gt;Manually verify that &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore.pingpublications.com&lt;/code&gt; is accessible and functional.&lt;/li&gt;
  &lt;li&gt;Confirm that critical dependencies are functional and also connected (database and CDN).&lt;/li&gt;
&lt;/ol&gt;

&lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;PURPOSE&lt;/strong&gt;: Indicates the test procedures necessary to ensure the system is functioning normally.&lt;/p&gt;

&lt;h6 id=&quot;resume-procedure&quot;&gt;Resume Procedure&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Service is now fully restored.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;notice--tip&quot;&gt;&lt;strong&gt;PURPOSE&lt;/strong&gt;: For more complex systems this final procedure should provide steps for resuming normal service.&lt;/p&gt;

&lt;h4 id=&quot;4-create-a-critical-dependency-failover-playbook&quot;&gt;4. Create a Critical Dependency Failover Playbook&lt;/h4&gt;

&lt;h5 id=&quot;scenario-database-failure&quot;&gt;Scenario: Database Failure&lt;/h5&gt;

&lt;h6 id=&quot;disaster-recovery-leads-1&quot;&gt;Disaster Recovery Leads&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Primary: Alice, Director of Technology&lt;/li&gt;
  &lt;li&gt;Secondary: Bob, Lead Developer, Bookstore API&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;severity-1&quot;&gt;Severity&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Critical&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-procedure-overview-1&quot;&gt;Recovery Procedure Overview&lt;/h6&gt;

&lt;ol&gt;
  &lt;li&gt;Manually verify database availability through Amazon RDS monitoring.&lt;/li&gt;
  &lt;li&gt;If unavailable, restart.&lt;/li&gt;
  &lt;li&gt;If still unavailable, manually propagate replica.&lt;/li&gt;
  &lt;li&gt;If necessary, restore from the most recent snapshot.&lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;basic-assumptions-1&quot;&gt;Basic Assumptions&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Amazon RDS is online and functional.&lt;/li&gt;
  &lt;li&gt;Database backups are available.&lt;/li&gt;
  &lt;li&gt;AWS Support contact is available for additional assistance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-time-objective-1&quot;&gt;Recovery Time Objective&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;12 Hours&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-point-objective-1&quot;&gt;Recovery Point Objective&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;24 Hours&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-platform-1&quot;&gt;Recovery Platform&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;PostgreSQL 10.4 database with identical configuration running on Amazon RDS with minimal &lt;code class=&quot;highlighter-rouge&quot;&gt;us-west-2a&lt;/code&gt; Availability Zone.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-procedure-1&quot;&gt;Recovery Procedure&lt;/h6&gt;

&lt;ol&gt;
  &lt;li&gt;Disaster recovery team member should manually verify database availability through Amazon RDS monitoring.&lt;/li&gt;
  &lt;li&gt;Manually restart the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db&lt;/code&gt; instance.
    &lt;ul&gt;
      &lt;li&gt;If &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db&lt;/code&gt; is back online, proceed to &lt;em&gt;Resume Procedure&lt;/em&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db&lt;/code&gt; remains unavailable manual propagate a replica Amazon RDS PostgreSQL 10.4 instance.&lt;/li&gt;
  &lt;li&gt;If replacement created, update DNS routing on Amazon Route 53 for &lt;code class=&quot;highlighter-rouge&quot;&gt;db.bookstore.pingpublications.com&lt;/code&gt; endpoint.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;(Optional)&lt;/em&gt;: Restore data from the most recent snapshot within acceptable RPO.&lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;test-procedure-1&quot;&gt;Test Procedure&lt;/h6&gt;

&lt;ol&gt;
  &lt;li&gt;Manually confirm a connection to public &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db&lt;/code&gt; endpoint (&lt;code class=&quot;highlighter-rouge&quot;&gt;db.bookstore.pingpublications.com&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;Confirm that &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api&lt;/code&gt; can access the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-db&lt;/code&gt; instance.&lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;resume-procedure-1&quot;&gt;Resume Procedure&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Service is now fully restored.
    &lt;ul&gt;
      &lt;li&gt;If necessary, perform manual data recovery.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;scenario-cdn-failure&quot;&gt;Scenario: CDN Failure&lt;/h5&gt;

&lt;h6 id=&quot;disaster-recovery-leads-2&quot;&gt;Disaster Recovery Leads&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Primary: Alice, Director of Technology&lt;/li&gt;
  &lt;li&gt;Secondary: Christina, Site Reliability Engineer&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;severity-2&quot;&gt;Severity&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Critical&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-procedure-overview-2&quot;&gt;Recovery Procedure Overview&lt;/h6&gt;

&lt;ol&gt;
  &lt;li&gt;Manual verification of applicable Amazon S3 bucket.&lt;/li&gt;
  &lt;li&gt;If unavailable, manually recreate bucket and upload a backup snapshot of static data.&lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;basic-assumptions-2&quot;&gt;Basic Assumptions&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Amazon S3 is online and functional.&lt;/li&gt;
  &lt;li&gt;Static asset backups are available.&lt;/li&gt;
  &lt;li&gt;Static asset collection can be performed remotely from the EC2 &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api&lt;/code&gt; server or locally via Django &lt;code class=&quot;highlighter-rouge&quot;&gt;manage.py collectstatic&lt;/code&gt; command.&lt;/li&gt;
  &lt;li&gt;AWS Support contact is available for additional assistance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-time-objective-2&quot;&gt;Recovery Time Objective&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;24 Hours&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-point-objective-2&quot;&gt;Recovery Point Objective&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;24 Hours&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-platform-2&quot;&gt;Recovery Platform&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Amazon S3 &lt;code class=&quot;highlighter-rouge&quot;&gt;private&lt;/code&gt; bucket accessible by administrator AWS account.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;recovery-procedure-2&quot;&gt;Recovery Procedure&lt;/h6&gt;

&lt;ol&gt;
  &lt;li&gt;Team member manually verifies Amazon S3 &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com&lt;/code&gt; bucket exists, is accessible, and contains all static content.&lt;/li&gt;
  &lt;li&gt;Manually recreate &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com&lt;/code&gt; bucket.&lt;/li&gt;
  &lt;li&gt;Manually upload all static content to &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com&lt;/code&gt; bucket.&lt;/li&gt;
  &lt;li&gt;If &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com&lt;/code&gt; bucket exists but is non-functional, manually create the bucket, upload static content, and route the system to backup.&lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;test-procedure-2&quot;&gt;Test Procedure&lt;/h6&gt;

&lt;ol&gt;
  &lt;li&gt;Confirm all static content exists in &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com&lt;/code&gt; Amazon S3 bucket.&lt;/li&gt;
  &lt;li&gt;Confirm public endpoint (&lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com/static&lt;/code&gt;) is accessible for static content.&lt;/li&gt;
  &lt;li&gt;Confirm that &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api&lt;/code&gt; can access &lt;code class=&quot;highlighter-rouge&quot;&gt;cdn.bookstore.pingpublications.com&lt;/code&gt; bucket and content.&lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;resume-procedure-2&quot;&gt;Resume Procedure&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;Service is now fully restored.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;5-create-a-non-critical-dependency-failover-playbook&quot;&gt;5. Create a Non-Critical Dependency Failover Playbook&lt;/h4&gt;

&lt;p&gt;The &lt;strong&gt;Bookstore&lt;/strong&gt; example app doesn’t have any non-critical dependencies at the moment given its simple architecture (&lt;code class=&quot;highlighter-rouge&quot;&gt;CDN &amp;gt; API Server &amp;lt; Database&lt;/code&gt;).  However, progressing through each resiliency stage will &lt;em&gt;require&lt;/em&gt; additional systems and services to maintain failure resilience, which will inherently add non-critical dependencies.&lt;/p&gt;

&lt;h3 id=&quot;complete-and-available-prerequisites&quot;&gt;Complete and Available Prerequisites&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Status: &lt;strong&gt;Complete&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All prerequisites for the &lt;strong&gt;Bookstore&lt;/strong&gt; app have been met and all documentation has been dispersed among every member of the team.&lt;/p&gt;

&lt;h3 id=&quot;team-wide-agreement-on-playbooks-1&quot;&gt;Team-Wide Agreement on Playbooks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Status: &lt;strong&gt;Complete&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Every team member has agreed on the playbook/scenarios defined above.&lt;/p&gt;

&lt;h3 id=&quot;manually-execute-a-failover-exercise-1&quot;&gt;Manually Execute a Failover Exercise&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Status: &lt;strong&gt;Complete&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this stage of the &lt;strong&gt;Bookstore&lt;/strong&gt; app, we’ve manually performed the &lt;a href=&quot;#scenario-bookstore-api-failure&quot;&gt;Scenario: Bookstore API Failure&lt;/a&gt; exercise.&lt;/p&gt;

&lt;p&gt;Full manual restoration of the &lt;code class=&quot;highlighter-rouge&quot;&gt;bookstore-api&lt;/code&gt; EC2 instance and the &lt;strong&gt;Bookstore&lt;/strong&gt; app resulted in approximately &lt;code class=&quot;highlighter-rouge&quot;&gt;30 minutes&lt;/code&gt; of downtime.  This is well under the initial RTO/RPO goals so we can reasonably update the playbooks.  However, this manual process is still clunky and prone to errors, so there’s plenty of room for improvement.&lt;/p&gt;

&lt;h2 id=&quot;resiliency-stage-1-completion&quot;&gt;Resiliency Stage 1 Completion&lt;/h2&gt;

&lt;p&gt;This post laid the groundwork for how to implement resilience engineering practices through thoughtfully-designed dependency identification and disaster recovery playbooks.  We also broke down the requirements and steps of &lt;strong&gt;Resiliency Stage 1&lt;/strong&gt;, which empowers your team to begin the journey toward a highly-resilient system.  Stay tuned to the &lt;a href=&quot;https://www.gremlin.com/blog/&quot;&gt;Gremlin Blog&lt;/a&gt; for additional posts that will break down the four remaining &lt;strong&gt;Stages of Resiliency&lt;/strong&gt;!&lt;/p&gt;</content><author><name>Gabe Wyatt</name></author><category term="resiliency" /><category term="staging" /></entry><entry><title type="html">Content Pitches</title><link href="http://localhost:4000/gremlin-blog-posts/gremlin/content-pitches/" rel="alternate" type="text/html" title="Content Pitches" /><published>2018-10-08T00:00:00-07:00</published><updated>2018-10-08T00:00:00-07:00</updated><id>http://localhost:4000/gremlin-blog-posts/gremlin/content-pitches</id><content type="html" xml:base="http://localhost:4000/gremlin-blog-posts/gremlin/content-pitches/">&lt;h2 id=&quot;gremlin-docs-update&quot;&gt;Gremlin Docs Update&lt;/h2&gt;

&lt;h3 id=&quot;integrate-gremlin-help-style-guidelines&quot;&gt;Integrate Gremlin Help Style Guidelines&lt;/h3&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: Update overall &lt;a href=&quot;https://help.gremlin.com/&quot;&gt;Gremlin documentation&lt;/a&gt; to better adhere to a singular documentation style, with the aim of maintaining consistency across both current and future content.&lt;/p&gt;

&lt;p&gt;While many style guides exist (and Gremlin may have a private guide already in use), the &lt;a href=&quot;https://developers.google.com/style/&quot;&gt;Google Developer Documentation Style Guide&lt;/a&gt; is a good generalized guide to take guidance from.  While much of that particular guide may not be relevant to Gremlin documentation, having consistent techniques helps determine when its appropriate to use elements like &lt;strong&gt;bold&lt;/strong&gt;, &lt;em&gt;italic&lt;/em&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;inline code&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;code blocks&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;hyphenated-file.names&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;CamelCase&lt;/code&gt; vs &lt;code class=&quot;highlighter-rouge&quot;&gt;lowercase&lt;/code&gt;, and so forth.&lt;/p&gt;

&lt;p&gt;This process could also be part of other cleanup/update efforts, as seen below.&lt;/p&gt;

&lt;h3 id=&quot;gremlin-api-reference&quot;&gt;Gremlin API Reference&lt;/h3&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: Update, cleanup, and expand the &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API Reference&lt;/a&gt;, in order to give public visitors a better understanding of its capabilities.&lt;/p&gt;

&lt;p&gt;Cleanup to fix a lot of formatting inconsistencies (random headers, ordering, improper casing, etc).  Update to ensure no existing information is out of date with current practices.  Then expand document to include more robust information.  This could include adding additional &lt;strong&gt;Attack&lt;/strong&gt; examples, blowing out valid flags and what they accomplish, including API examples beyond just &lt;strong&gt;Attacks&lt;/strong&gt; (e.g. &lt;strong&gt;Containers&lt;/strong&gt;, &lt;strong&gt;Reports&lt;/strong&gt;, &lt;strong&gt;Schedules&lt;/strong&gt;, etc).  Since the &lt;a href=&quot;https://app.gremlin.com/api&quot;&gt;https://app.gremlin.com/api&lt;/a&gt; API playground is locked behind an active account, expanding the &lt;a href=&quot;https://help.gremlin.com/api&quot;&gt;https://help.gremlin.com/api/&lt;/a&gt; documentation would allow public visitors to get a better sense of everything that can be accomplished with the API.&lt;/p&gt;

&lt;h3 id=&quot;gremlin-installation-tutorials&quot;&gt;Gremlin Installation Tutorials&lt;/h3&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: Update and expand &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin Help&lt;/a&gt; documentation, to ensure content is up to date and messaging is consistent across documentation.&lt;/p&gt;

&lt;p&gt;General update process would include going through each &lt;code class=&quot;highlighter-rouge&quot;&gt;how to&lt;/code&gt; tutorial to ensure every step is still relevant to modern Gremlin, making any necessary adjustments along the way.  Some minor adjustment examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Update each tutorial &lt;code class=&quot;highlighter-rouge&quot;&gt;Introduction&lt;/code&gt; to be consistent. For many tutorials begins with &lt;code class=&quot;highlighter-rouge&quot;&gt;Gremlin’s “Failure as a Service” makes it easy to find weaknesses in your system...&lt;/code&gt;, but a handful have a different introduction (&lt;a href=&quot;https://help.gremlin.com/install-gremlin-aws/&quot;&gt;AWS&lt;/a&gt;, &lt;a href=&quot;https://help.gremlin.com/install-gremlin-docker-ubuntu-1604/&quot;&gt;Docker&lt;/a&gt;, etc).&lt;/li&gt;
  &lt;li&gt;Update mentions of Gremlin auto-populated tags.  For example, &lt;a href=&quot;https://help.gremlin.com/install-gremlin-aws/#step-3-registering-with-gremlin&quot;&gt;AWS tutorial&lt;/a&gt; mentions a couple tags, but Gremlin now auto-generates 7+ tags for EC2 instances.&lt;/li&gt;
  &lt;li&gt;Add screenshots where missing to expand content.  For example, the &lt;a href=&quot;https://help.gremlin.com/install-gremlin-docker-ubuntu-1604/&quot;&gt;Docker tutorial&lt;/a&gt; is very in-depth and includes many images to accompany text, whereas other tutorials are more limited.&lt;/li&gt;
  &lt;li&gt;Tutorials can be expanded with additional information, such as alternative techniques (i.e. how to create &lt;strong&gt;Attacks&lt;/strong&gt; via the API in addition to the web UI).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gremlin-installation---video-tutorials&quot;&gt;Gremlin Installation - Video Tutorials&lt;/h3&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: Series of video walkthrough tutorials – with accompanying voiceover – showing how to install and use Gremlin on a given infrastructure/technology.&lt;/p&gt;

&lt;p&gt;Video guides offer an alternative learning method for visitors, particularly those trying to determine what Gremlin is capable of and if its appropriate to their use case.  For those that prefer watching video to reading text, simple video tutorials that walkthrough the basic process of installing and using Gremlin on a given technology may be valuable.  While video guides can be published as standalone content to drive traffic, embedding accompanying video guides into existing documentation content would also be beneficial.&lt;/p&gt;

&lt;p&gt;I have a professional microphone, recording equipment, and a lot of editing experience with Adobe Premiere Pro and After Effects.  I’ve created hundreds of commentary guides (for personal gaming-related projects) in the past, so I am certainly capable of handling the entirety of such a project, from inception and script creation to recording and voiceover to final editing and rendering.  &lt;em&gt;Note: I would need access to Gremlin imaging/PSD files or existing video clip to add a simple Gremlin-branded video introduction splash screen.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-to-install-gremlin-on-openshift&quot;&gt;How to Install Gremlin on OpenShift&lt;/h2&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: A walkthrough tutorial for setting up OpenShift and installing/using Gremlin on it.&lt;/p&gt;

&lt;p&gt;I came close to creating such a guide while writing up the &lt;a href=&quot;https://gabestah.github.io/gremlin-chaos-monkey/alternatives/openshift/&quot;&gt;Chaos Monkey Alternatives - OpenShift&lt;/a&gt; chapter, but didn’t have enough time to dedicate to troubleshoot the issues and finish up the process.  This guide would be similar to &lt;a href=&quot;https://www.gremlin.com/community/tutorials/how-to-install-and-use-gremlin-with-kubernetes/&quot;&gt;How to Install and Use Gremlin with Kubernetes&lt;/a&gt;, since both require the use of a DaemonSet to get Gremlin deployed on each attackable machine.&lt;/p&gt;

&lt;h2 id=&quot;chaos-tooling-showdown-x-vs-y-series&quot;&gt;Chaos Tooling Showdown: X vs Y [Series]&lt;/h2&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: A blog series in which each article compares two popular Chaos Engineering tools.&lt;/p&gt;

&lt;p&gt;The purpose of these pieces would be to try to provide a factual comparison of two similar tools skewed toward running Chaos Experiments and other general SRE tasks, while allowing the reader to decide which is better.  Each article might provide the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Brief overview and explanation of each tool.&lt;/li&gt;
  &lt;li&gt;Technical tutorial for basic installation, configuration, and usage of both tools.&lt;/li&gt;
  &lt;li&gt;Comparison of each tool, perhaps using Advantage/Disadvantage list illustrating scenarios where one tool may be preferable.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: It would be ideal to remain as neutral as possible within the tone and content of these articles, to avoid appearing too biased (especially when comparing Gremlin to other tools).  Even a little bit of humility can go a long way.&lt;/p&gt;

&lt;h3 id=&quot;gremlin-vs-chaos-toolkit&quot;&gt;Gremlin vs Chaos Toolkit&lt;/h3&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: As discussed above, do a deep dive into both Gremlin and Chaos Toolkit, providing a basic installation and usage tutorial, and then comparing the advantages and disadvantages to each tool in a handful of scenarios.&lt;/p&gt;

&lt;p&gt;For example, we could show that for &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS&lt;/code&gt; both tools can fairly easily handle &lt;code class=&quot;highlighter-rouge&quot;&gt;EC2&lt;/code&gt; instance shutdowns, while Gremlin can perform network attacks that Chaos Toolkit cannot.&lt;/p&gt;

&lt;h2 id=&quot;chaos-engineering-through-staged-resiliency-series&quot;&gt;Chaos Engineering Through Staged Resiliency [Series]&lt;/h2&gt;

&lt;h3 id=&quot;status-complete&quot;&gt;STATUS: &lt;strong&gt;Complete&lt;/strong&gt;&lt;/h3&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: Discuss the danger of performing random Chaos Experiments without first establishing a disaster recovery playbook safety net.&lt;/p&gt;

&lt;p&gt;Rather than defining system resiliency as a binary “yes” or “no”, outline how resiliency can be thought of as a series of defined “levels.”  As resiliency level rises, support costs dramatically fall.  Each post focuses on a specific “resiliency level” and defines what it is, how it is implemented, and provides examples of what such a level of resiliency might look like in an organization.  Overall discussion emphasizes the importance of allowing teams to work towards “climbing the ladder” of resiliency, rather than trying to make a sudden leap from the bottom to the top.&lt;/p&gt;

&lt;p&gt;Sources:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;https://medium.com/walmartlabs/charting-a-path-to-software-resiliency-38148d956f4a&lt;/li&gt;
  &lt;li&gt;https://www.youtube.com/watch?v=4Gy_5EQMrB4&amp;amp;index=5&amp;amp;list=PLLIx5ktghjqKtZdfDDyuJrlhC-ICfhVAN&amp;amp;t=0s&lt;/li&gt;
  &lt;li&gt;https://www.slideshare.net/secret/jj7mkHy5JKajpm?from_action=save&lt;/li&gt;
  &lt;li&gt;https://www.infoq.com/articles/chaos-engineering-conf&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Roles of Cloud Platform team:&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Centralize the best practices, tools and techniques&lt;/li&gt;
    &lt;li&gt;Enforce and facilitate gamedays&lt;/li&gt;
    &lt;li&gt;Create tools for every phase of the CD pipeline&lt;/li&gt;
    &lt;li&gt;Monitor acceptable levels of resiliency and call out “risks”&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;5 Stages of Resiliency:&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;1: High revenue loss, high support costs, and low resiliency.&lt;/li&gt;
    &lt;li&gt;5: Low revenue loss, low support costs, and high resiliency.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Prerequisites:&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;Create your DR failover playbook.&lt;/li&gt;
    &lt;li&gt;Define critical dependencies.&lt;/li&gt;
    &lt;li&gt;Compose playbook for critical dependency failures.&lt;/li&gt;
    &lt;li&gt;Define non-critical dependencies.&lt;/li&gt;
    &lt;li&gt;Define thresholds at which non-critical dependency failures will impact system.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;level-1manualgetting-agreement-from-all-parties-and-dr-failover&quot;&gt;Level 1 — Manual — Getting agreement from all parties and DR failover&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;All of the pre-requisites stored in a single well-defined place&lt;/li&gt;
    &lt;li&gt;Agreement on playbooks to be used by Devs, Testers, Operations, Stakeholders&lt;/li&gt;
    &lt;li&gt;Manual exercise that validates the DR failover playbook&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;level-2manualcritical-dependency-failures-in-pre-prod&quot;&gt;Level 2 — Manual — critical dependency failures in pre-prod&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;All of level 1 requirements, plus&lt;/li&gt;
    &lt;li&gt;Run a failure test for critical dependencies in a non-prod environment&lt;/li&gt;
    &lt;li&gt;Publish test results to team, stakeholders&lt;/li&gt;
    &lt;li&gt;Manual tests are acceptable&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;level-3manual-and-automaticregular-exercises&quot;&gt;Level 3 — Manual and Automatic — Regular exercises&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;All of level 2 requirements, plus&lt;/li&gt;
    &lt;li&gt;Run tests regularly on a cadence (at least once every 4–5 weeks)&lt;/li&gt;
    &lt;li&gt;Publish results to dashboards to track resiliency over time&lt;/li&gt;
    &lt;li&gt;Run at least one resiliency exercise (failure injection) in production environment&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;level-4automatedfully-automated-in-pre-prod&quot;&gt;Level 4 — Automated — fully automated in pre-prod&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;All of level 3 requirements, plus&lt;/li&gt;
    &lt;li&gt;Automated resiliency testing in non-prod environment&lt;/li&gt;
    &lt;li&gt;Semi-automated DR failover scripts (minimal human supervision required)&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;level-5full-automation&quot;&gt;Level 5 — Full automation&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;All of level 4 requirements, plus&lt;/li&gt;
    &lt;li&gt;Automated resiliency testing fully integrated into CI/CD environment&lt;/li&gt;
    &lt;li&gt;Resiliency failure results in build failure&lt;/li&gt;
    &lt;li&gt;Automated resiliency testing and DR failover testing enabled in production environment&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;how-to-build-effective-disaster-recovery-strategies&quot;&gt;How to Build Effective Disaster Recovery Strategies&lt;/h2&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: 1 - 2 articles discussing &lt;strong&gt;Disaster Recovery&lt;/strong&gt; techniques including guides for implementing a basic disaster recovery plan on the more common platforms (AWS, Azure, etc).&lt;/p&gt;

&lt;p&gt;Articles will also explore subsets of disaster recovery such as failover playbooks and how Chaos practices (e.g. gamedays) fit into proper disaster recovery strategies.&lt;/p&gt;

&lt;h2 id=&quot;deploying-a-chaos-engineered-stack-with-ansible-playbooks&quot;&gt;Deploying a Chaos Engineered Stack with Ansible Playbooks&lt;/h2&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: Article(s) providing a step-by-step tutorial for deploying a (simple) application stack in the cloud using &lt;a href=&quot;https://docs.ansible.com/ansible/latest/user_guide/playbooks.html&quot;&gt;Ansible Playbooks&lt;/a&gt; that &lt;em&gt;includes&lt;/em&gt; Gremlin ready to go (“pre-installed”) as a Chaos Engineering solution.&lt;/p&gt;

&lt;p&gt;Total length is unknown but would likely be rather in-depth as Ansible playbooks can get complex.  Gremlin auto-inclusion would need to be tested to see how feasible/workable this idea is.&lt;/p&gt;

&lt;h2 id=&quot;uncategorized&quot;&gt;Uncategorized&lt;/h2&gt;

&lt;h3 id=&quot;blamelesscom-ideas&quot;&gt;Blameless.com Ideas&lt;/h3&gt;

&lt;p class=&quot;notice--warning&quot;&gt;&lt;strong&gt;Pitch&lt;/strong&gt;: &lt;em&gt;&lt;strong&gt;(TBD)&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ag (Slack): “each of the points on &lt;a href=&quot;https://blameless.com/why-blameless/&quot;&gt;this page&lt;/a&gt; could probably be incorporated into a blog post”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;DEVOPS IS REVOLUTIONIZING SOFTWARE DELIVERY.
It knocks down barriers in software development, changing how engineering and operations teams work together. It promotes greater communication, faster release cycles, and better code delivery to end-users.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;WHAT’S MISSING IS THE INSTRUCTION MANUAL.
How do you bridge the gap between development and operations? How do you ensure stability as you release more frequently? How do you measure success?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;SRE ANSWERS THE HOW.
SRE (Site Reliability Engineering) makes software realiable in highly complex and ever-changing systems. SRE is implemented by the largest technology companies and being adopted by teams of all sizes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;WHY BLAMELESS FOR SRE
Blameless is the first step towards building your SRE practice.
Our reliability platform helps teams quickly implement SRE best practices, workflows and tooling, resulting in more effective:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Collaboration &amp;amp; Communication
Resolve incidents faster by ensuring clear roles &amp;amp; processes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Post-Incident Workflows
Prevent incident recurrence by learning from key data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Insights &amp;amp; Visibility
Measure reliability with dashboards, data &amp;amp; reports and get insights on how to improve.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;REPORTS &amp;amp; DASHBOARDS
Reliability metrics make it easy to track improvements in SLAs, org health and feature velocity over time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;INTEGRATIONS WITH EXISTING TOOLS
Blameless handles tool and data sprawl by integrating into your existing incident, risk and problem management workflow.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;CHAT AND VIDEO INCIDENT RESOLUTION
Resolve incidents faster with incident roles, playbooks, war room transcriptions, real time timeline generation and more.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;INCIDENT KNOWLEDGE MANAGEMENT
Learn painlessly and quickly using our retrospective tooling and workflow. Automatically capture incident data, build timelines, and keep a record of all prior incidents.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;COMMUNICATION MANAGEMENT
Protect your brand and build trust by keeping internal and external stakeholders notified when an incident occurs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;AUTOMATED PLAYBOOKS
Take SRE actions across your infrastructure. Schedule orchestration jobs, build playbooks and automate best practices.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Gabe Wyatt</name></author><category term="content" /><category term="idea" /><summary type="html">Content pitches and ideas for Gremlin.</summary></entry><entry><title type="html">Migrating to the Cloud Is Chaotic. Embrace It.</title><link href="http://localhost:4000/gremlin-blog-posts/chaos-engineering/migrating-cloud-chaotic-embrace/" rel="alternate" type="text/html" title="Migrating to the Cloud Is Chaotic. Embrace It." /><published>2018-10-05T00:00:00-07:00</published><updated>2018-10-05T00:00:00-07:00</updated><id>http://localhost:4000/gremlin-blog-posts/chaos-engineering/migrating-cloud-chaotic-embrace</id><content type="html" xml:base="http://localhost:4000/gremlin-blog-posts/chaos-engineering/migrating-cloud-chaotic-embrace/">&lt;p class=&quot;notice--danger&quot;&gt;Why organizations planning to migrate to the cloud should embrace Chaos Engineering as a thoughtful strategy to avoid pain down the road.&lt;/p&gt;

&lt;p&gt;Migrating to the cloud is an intimidating prospect and understandably so – there’s a lot that will change in your systems from on-prem to the cloud, and changes can mean instability in your systems.&lt;/p&gt;

&lt;p class=&quot;notice--success&quot;&gt;How can you ensure your software will be safe after migrating to the cloud?  How do you combat the cloud’s chaotic nature while ensuring a resilient and stable system?  &lt;strong&gt;By intentionally inducing Chaos well before migration begins.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It sounds counter-intuitive to perform Chaos Engineering while your team is actively migrating to the cloud. Wouldn’t that just add failure and slow down an already challenging process? The reality is that when you’re migrating to the cloud Chaos Engineering is the best way to be confident that you’ve tested how your new system will behave once you switch traffic over. By performing Chaos Experiments on the environment you’re migrating into, you’ll identify weaknesses with plenty of time to mitigate them.&lt;/p&gt;

&lt;p&gt;In 2016, groups from the University of Chicago and Surya University jointly published an in-depth &lt;a href=&quot;http://ucare.cs.uchicago.edu/pdf/socc16-cos.pdf&quot;&gt;cloud outage study&lt;/a&gt; that examined the causes of service outages among 32 of the most popular Internet services between 2009 and 2015.  This post will go into a number of these outages and provide tutorials to run Chaos Experiments and proactively identify potential issues before they turn into production outages.&lt;/p&gt;

&lt;p class=&quot;notice--success&quot;&gt;The &lt;a href=&quot;http://ucare.cs.uchicago.edu/pdf/socc16-cos.pdf&quot;&gt;study&lt;/a&gt; found that the &lt;em&gt;majority&lt;/em&gt; of unplanned outages (16%) are caused by failures during upgrade and migration processes.&lt;/p&gt;

&lt;h2 id=&quot;managing-heavy-cpu-load&quot;&gt;Managing Heavy CPU Load&lt;/h2&gt;

&lt;p&gt;An overloaded CPU can quickly create bottlenecks and cause failures within most architectures. In a distributed cloud environment, instability in a single system can quickly cascade into problems elsewhere down the chain. Proper CPU resilience testing helps to determine which existing systems are currently resilient to a CPU failure, and which need to be prioritized for upgrade and migration necessary to maintain a stable stack.&lt;/p&gt;

&lt;h3 id=&quot;why-it-matters-hotmail--outlook-2013&quot;&gt;Why It Matters: Hotmail &amp;amp; Outlook (2013)&lt;/h3&gt;

&lt;p&gt;Microsoft’s customer migration from Hotmail to the new Outlook.com was generally executed without a hitch.  Unfortunately, on March 12th, 2013 a failed firmware upgrade &lt;a href=&quot;https://www.microsoft.com/en-us/microsoft-365/blog/2013/03/13/details-of-the-hotmail-outlook-com-outage-on-march-12th/&quot;&gt;caused&lt;/a&gt; a 16+ hour outage for some customers trying to access SkyDrive, Hotmail, and Outlook.com services.&lt;/p&gt;

&lt;p&gt;Microsoft reported that the firmware update “failed […] in an unexpected way,” but did not provide any additional details on the root cause.  However, this failure resulted in rapid, substantial temperature spikes within the datacenter.  The increase in temperature triggered automatic safeguards for a large portion of the servers within the datacenter.  Consequently, the safeguards prevented mailbox access for affected customers, and also prevented automatic failover processes from performing their normal duties.&lt;/p&gt;

&lt;p&gt;Without additional details on the root cause and the specific impacts, we can only speculate, but a temperature spike points toward a dramatic spike in CPU load for some servers within the datacenter.  In this particular instance, it’s possible that pre-emptive Chaos Engineering may have allowed engineers to simulate similar heavy CPU load scenarios.&lt;/p&gt;

&lt;h3 id=&quot;performing-a-cpu-attack-with-gremlin&quot;&gt;Performing a CPU Attack with Gremlin&lt;/h3&gt;

&lt;p&gt;A Gremlin &lt;strong&gt;CPU Attack&lt;/strong&gt; consumes 100% of the specified CPU cores on the target system.  The &lt;strong&gt;CPU Attack&lt;/strong&gt; is a great way to test the stability of the targeted machine – along with its critical dependencies – when the CPU is overloaded.&lt;/p&gt;

&lt;h4 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://help.gremlin.com/installation/&quot;&gt;Install Gremlin&lt;/a&gt; on the target machine.&lt;/li&gt;
  &lt;li&gt;Retrieve your &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API Token&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API&lt;/a&gt; &lt;strong&gt;CPU Attack&lt;/strong&gt; accepts the following arguments.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Short Flag&lt;/th&gt;
      &lt;th&gt;Long Flag&lt;/th&gt;
      &lt;th&gt;Purpose&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-c&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--cores&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Number of CPU cores to attack.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-l&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--length&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Attack duration (in seconds).&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Most &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API&lt;/a&gt; calls accept a JSON body payload, which specifies critical arguments.  In all the following examples you’ll be creating a local &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/&amp;lt;attack-name&amp;gt;.json&lt;/code&gt; file to store the API attack arguments.  You’ll then pass those arguments along to the API request.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;On your local machine, start by creating the &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/cpu.json&lt;/code&gt; file and paste the following JSON into it.  This will attack a single core for &lt;code class=&quot;highlighter-rouge&quot;&gt;30&lt;/code&gt; seconds.&lt;/p&gt;

    &lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cpu&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;30&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;target&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Random&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create the new &lt;strong&gt;Attack&lt;/strong&gt; by passing the JSON from &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/cpu.json&lt;/code&gt; to the &lt;code class=&quot;highlighter-rouge&quot;&gt;https://api.gremlin.com/v1/attacks/new&lt;/code&gt; API endpoint.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; curl &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$GREMLIN_API_TOKEN&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; https://api.gremlin.com/v1/attacks/new &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;@attacks/cpu.json&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;a href=&quot;https://app.gremlin.com/attacks&quot;&gt;Gremlin Web UI&lt;/a&gt; also shows the &lt;strong&gt;Attack&lt;/strong&gt; that was created.&lt;/p&gt;

    &lt;p&gt;&lt;img alt=&quot;Gremlin Web UI CPU Attack&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/migrating-cloud-chaotic-embrace/web-ui-cpu-attack-a4b0c805d6d2e406611908b22a848de1cf03193d1db5ae434fc14f9905c200b3.png&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On the targeted machine you’ll see that one CPU core is maxed out.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; htop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;&lt;img alt=&quot;htop CPU Maximized&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/migrating-cloud-chaotic-embrace/htop-cpu-max-22d1f36521ae859ff70072681c19c490d4f9d27aadca4e03ddddaa47f6dc69d8.png&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p class=&quot;notice--info&quot;&gt;If you wish to attack a &lt;em&gt;specific&lt;/em&gt; &lt;strong&gt;Client&lt;/strong&gt; just change the &lt;code class=&quot;highlighter-rouge&quot;&gt;target : type&lt;/code&gt; argument value to &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;Exact&quot;&lt;/code&gt; and add the &lt;code class=&quot;highlighter-rouge&quot;&gt;target : exact&lt;/code&gt; field with a list of target &lt;strong&gt;Clients&lt;/strong&gt;.  A &lt;strong&gt;Client&lt;/strong&gt; is identified on Gremlin as the &lt;code class=&quot;highlighter-rouge&quot;&gt;GREMLIN_IDENTIFIER&lt;/code&gt; for the instance, which can also be specified in a local environment variable when running the &lt;code class=&quot;highlighter-rouge&quot;&gt;gremlin init&lt;/code&gt; command.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cpu&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;30&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;target&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;aws-nginx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;handling-storage-disk-limitations&quot;&gt;Handling Storage Disk Limitations&lt;/h2&gt;

&lt;p&gt;Migrating to a new system frequently requires moving volumes across disks and to other cloud-based storage layers.  It’s vital to determine if the new storage system can handle the increase in volume that the migration will require.  Additionally, to properly test the resilience of the system you’ll also want to test how the system reacts when volumes are overburdened or unavailable.&lt;/p&gt;

&lt;h3 id=&quot;why-it-matters-instapaper-2017&quot;&gt;Why It Matters: Instapaper (2017)&lt;/h3&gt;

&lt;p&gt;In February 2017 the popular web content bookmarking service Instapaper suffered &lt;a href=&quot;https://medium.com/making-instapaper/instapaper-outage-cause-recovery-3c32a7e9cc5f&quot;&gt;a service outage&lt;/a&gt; due to a &lt;a href=&quot;https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Limits.html#RDS_Limits.FileSize&quot;&gt;2 TB file size limit&lt;/a&gt; within Instapaper’s Amazon RDS MySQL instance.&lt;/p&gt;

&lt;p&gt;This issue was unknown to Instapaper ever since their migration to AWS in 2013.  At that time, they migrated their database to MySQL on Amazon RDS, which was using a slightly outdated version of MySQL that enforced the 2 TB file size limit.  Even after attempting to upgrade to newer hardware and a newer MySQL version in March 2015, the original instance that contained the 2 TB limit was replicated, thereby retaining the underlying problem.&lt;/p&gt;

&lt;p&gt;Eventually, their database finally hit that limit in early 2017 and caused a day+ service outage.  As Instapaper points out in their &lt;a href=&quot;https://medium.com/making-instapaper/instapaper-outage-cause-recovery-3c32a7e9cc5f&quot;&gt;postmortem&lt;/a&gt;, it was difficult for the team to be aware of this limitation and potential issue ahead of time.  However, this unfortunate event illustrates the importance of properly testing data storage systems prior to migration.&lt;/p&gt;

&lt;h3 id=&quot;performing-a-disk-attack-with-gremlin&quot;&gt;Performing a Disk Attack with Gremlin&lt;/h3&gt;

&lt;p&gt;Gremlin’s &lt;strong&gt;Disk Attack&lt;/strong&gt; rapidly consumes disk space on the targeted machine, allowing you to test the resiliency of that machine and other related systems when unexpected disk failures occur.&lt;/p&gt;

&lt;h4 id=&quot;prerequisites-1&quot;&gt;Prerequisites&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://help.gremlin.com/installation/&quot;&gt;Install Gremlin&lt;/a&gt; on the target machine.&lt;/li&gt;
  &lt;li&gt;Retrieve your &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API Token&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API&lt;/a&gt; &lt;strong&gt;Disk Attack&lt;/strong&gt; accepts the following arguments.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Short Flag&lt;/th&gt;
      &lt;th&gt;Long Flag&lt;/th&gt;
      &lt;th&gt;Purpose&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-b&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--block-size&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The block size (in kilobytes) that are written.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-d&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--dir&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The directory that temporary files will be written to.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-l&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--length&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Attack duration (in seconds).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--percent&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The percentage of the volume to fill.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-w&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--workers&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The number of disk-write workers to run concurrently.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;On your local machine, start by creating the &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/disk.json&lt;/code&gt; file and paste the following JSON into it.  Be sure to change your target &lt;strong&gt;Client&lt;/strong&gt;.  This attack will fill &lt;code class=&quot;highlighter-rouge&quot;&gt;95%&lt;/code&gt; of the volume over the course of a &lt;code class=&quot;highlighter-rouge&quot;&gt;60-second&lt;/code&gt; attack using &lt;code class=&quot;highlighter-rouge&quot;&gt;2&lt;/code&gt; workers.&lt;/p&gt;

    &lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;disk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/tmp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;60&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-w&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-b&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-p&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;95&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;target&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;aws-nginx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;(Optional)&lt;/em&gt; Check the current disk usage on the target machine.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# OUTPUT&lt;/span&gt;
 Filesystem      Size  Used Avail Use% Mounted on
 /dev/xvda1      8.3G  1.4G  6.9G  17% /
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create the new &lt;strong&gt;Disk Attack&lt;/strong&gt; by passing the JSON from &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/disk.json&lt;/code&gt; to the &lt;code class=&quot;highlighter-rouge&quot;&gt;https://api.gremlin.com/v1/attacks/new&lt;/code&gt; API endpoint.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; curl &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$GREMLIN_API_TOKEN&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; https://api.gremlin.com/v1/attacks/new &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;@attacks/disk.json&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;a href=&quot;https://app.gremlin.com/attacks&quot;&gt;Gremlin Web UI&lt;/a&gt; now shows the &lt;strong&gt;Attack&lt;/strong&gt; that was created.&lt;/p&gt;

    &lt;p&gt;&lt;img alt=&quot;Gremlin Web UI Disk Attack&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/migrating-cloud-chaotic-embrace/web-ui-disk-attack-57c40e03b827748989ab14c9d7277c326e7fc3dab092ad569fee72d6069eb5d7.png&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Check the attack target’s current disk space, which will soon reach the specified percentage before Gremlin rolls back and returns the disk to the original state.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# OUTPUT&lt;/span&gt;
 Filesystem      Size  Used Avail Use% Mounted on
 /dev/xvda1      8.3G  7.9G  396M  96% /
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;evaluating-network-resiliency&quot;&gt;Evaluating Network Resiliency&lt;/h2&gt;

&lt;p&gt;While the majority of Internet service outages are caused by failures during migration and upgrade procedures, the aforementioned &lt;a href=&quot;http://ucare.cs.uchicago.edu/pdf/socc16-cos.pdf&quot;&gt;Why Does the Cloud Stop Computing?
Lessons from Hundreds of Service Outages&lt;/a&gt; study found that network problems are the second most common cause and account for some &lt;code class=&quot;highlighter-rouge&quot;&gt;15%&lt;/code&gt; of service outages.  Even architectures designed with network redundancies can experience multiple, cumulative network failures without proper testing and experimentation.  Moreover, most modern software relies on external networks to some degree, which means a network outage completely outside of your control could cause a failure to propagate throughout your system.&lt;/p&gt;

&lt;h3 id=&quot;why-it-matters-microsoft-office-365-2013&quot;&gt;Why It Matters: Microsoft Office 365 (2013)&lt;/h3&gt;

&lt;p&gt;On February 1st, 2013 a change to the Microsoft Online edge network prevented some internet traffic from reaching the Microsoft Office 365 service, which prevented customers from accessing Exchange and SharePoint services for a few hours.  While the &lt;a href=&quot;https://www.quadrotech-it.com/blog/feb-1-office-365-outage-incident-review-release/&quot;&gt;incident report&lt;/a&gt; doesn’t explicitly name the underlying change that caused the problem, it does state that a procedural error was unintentionally and automatically propagated to multiple devices within the Microsoft Online network, which “caused incorrect routing for a portion of the inbound internet traffic.”  Additionally, affected customers were unable to access administrative services within the &lt;strong&gt;Service Health Dashboard&lt;/strong&gt; (SHD) provided by Microsoft, but the backup process intended to provide support to customers that were unable to access the SHD did not work as well as expected.&lt;/p&gt;

&lt;p&gt;While this overall incident only lasted a few hours and affected a small subset of customers, it illustrates the importance of proper network resiliency testing prior to and during system migrations.  Chaos Experiments that cause networking failures – such as creating a black hole so certain traffic is halted – are a great way to test system stability under these unexpected conditions.&lt;/p&gt;

&lt;h3 id=&quot;performing-a-black-hole-attack-with-gremlin&quot;&gt;Performing a Black Hole Attack with Gremlin&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;Black Hole Attack&lt;/strong&gt; temporarily drops all traffic based on the parameters of the attack.  You can use a &lt;strong&gt;Black Hole Attack&lt;/strong&gt; to test routing protocols, loss of communication to specific hosts, port-based traffic, network device failure, and much more.&lt;/p&gt;

&lt;h4 id=&quot;prerequisites-2&quot;&gt;Prerequisites&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://help.gremlin.com/installation/&quot;&gt;Install Gremlin&lt;/a&gt; on the target machine.&lt;/li&gt;
  &lt;li&gt;Retrieve your &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API Token&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API&lt;/a&gt; &lt;strong&gt;Black Hole Attack&lt;/strong&gt; accepts the following arguments.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Short Flag&lt;/th&gt;
      &lt;th&gt;Long Flag&lt;/th&gt;
      &lt;th&gt;Purpose&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-d&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--device&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Network device through which traffic should be affected.  Defaults to the first device found.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-h&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--hostname&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Outgoing hostnames to affect.  Optionally, you can prefix a hostname with a caret (&lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;) to whitelist it.  It is recommended to include &lt;code class=&quot;highlighter-rouge&quot;&gt;^api.gremlin.com&lt;/code&gt; in the whitelist.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-i&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--ipaddress&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Outgoing IP addresses to affect.  Optionally, you can prefix an IP with a caret (&lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;) to whitelist it.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-l&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--length&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Attack duration (in seconds).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-n&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--ingress_port&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Only affect ingress traffic to these destination ports.  Ranges can also be specified (e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;8080-8085&lt;/code&gt;).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--egress_port&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Only affect egress traffic to these destination ports.  Ranges can also be specified (e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;8080-8085&lt;/code&gt;).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-P&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--ipprotocol&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Only affect traffic using this protocol.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Start by performing a test to establish a baseline.  The following command tests the response time of a request to &lt;code class=&quot;highlighter-rouge&quot;&gt;example.com&lt;/code&gt; (which has an IP address of &lt;code class=&quot;highlighter-rouge&quot;&gt;93.184.216.34&lt;/code&gt;).&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;time &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; /dev/null 93.184.216.34

 &lt;span class=&quot;c&quot;&gt;# OUTPUT&lt;/span&gt;
 real    0m0.025s
 user    0m0.009s
 sys     0m0.000s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On your local machine, create the &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/blackhole.json&lt;/code&gt; file and paste the following JSON into it.  Set your target &lt;strong&gt;Client&lt;/strong&gt; as necessary.  This attack creates a &lt;code class=&quot;highlighter-rouge&quot;&gt;30-second&lt;/code&gt; black hole that drops traffic to the &lt;code class=&quot;highlighter-rouge&quot;&gt;93.184.216.34&lt;/code&gt; IP address.&lt;/p&gt;

    &lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;blackhole&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;30&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-i&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;93.184.216.34&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-h&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^api.gremlin.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;target&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;aws-nginx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Execute the &lt;strong&gt;Black Hole Attack&lt;/strong&gt; by passing the JSON from &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/blackhole.json&lt;/code&gt; to the &lt;code class=&quot;highlighter-rouge&quot;&gt;https://api.gremlin.com/v1/attacks/new&lt;/code&gt; API endpoint.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; curl &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$GREMLIN_API_TOKEN&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; https://api.gremlin.com/v1/attacks/new &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;@attacks/blackhole.json&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On the target machine run the same timed &lt;code class=&quot;highlighter-rouge&quot;&gt;curl&lt;/code&gt; test as before.  It now hangs for approximately &lt;code class=&quot;highlighter-rouge&quot;&gt;30&lt;/code&gt; seconds until the black hole has been terminated and a response is finally received.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;time &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; /dev/null 93.184.216.34

 &lt;span class=&quot;c&quot;&gt;# OUTPUT&lt;/span&gt;
 real    0m31.623s
 user    0m0.013s
 sys     0m0.000s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You can also view the &lt;strong&gt;Attack&lt;/strong&gt; on the &lt;a href=&quot;https://app.gremlin.com/attacks&quot;&gt;Gremlin Web UI&lt;/a&gt; to confirm it functioned properly.&lt;/p&gt;

    &lt;p&gt;&lt;img alt=&quot;Gremlin Web UI Black Hole Attack&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/migrating-cloud-chaotic-embrace/web-ui-blackhole-attack-5568e6cf288a9ee0b6f17b6c0527fd80d2d917e83b2b513c3dc64a846389dbea.png&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;proper-memory-management&quot;&gt;Proper Memory Management&lt;/h2&gt;

&lt;p&gt;While most commonly-used cloud platforms provide auto-balancing and scaling services, it’s impossible to rely solely on these technologies to ensure your migrated software will remain stable and responsive.  Memory management is a crucial part of maintaining a healthy and inexpensive cloud stack.  An improper configuration or poorly tested system may not necessarily cause a system failure or outage, but even a tiny memory issue can add up to thousands of dollars in extra support costs.&lt;/p&gt;

&lt;p&gt;Performing Chaos Engineering before, during, and after cloud migration lets you test system failures when instances, containers, or nodes run out of memory.  This testing ensures your stack remains active and fully functional when an &lt;em&gt;unexpected&lt;/em&gt; memory leak occurs.&lt;/p&gt;

&lt;h3 id=&quot;why-it-matters-google-docs-2011&quot;&gt;Why It Matters: Google Docs (2011)&lt;/h3&gt;

&lt;p&gt;In early September 2011 Google Docs suffered a widespread, hour-long outage that prevented the majority of customers from accessing documents, drawings, lists, and App Scripts.  As Google &lt;a href=&quot;https://cloud.googleblog.com/2011/09/what-happened-to-google-docs-on.html&quot;&gt;later reported&lt;/a&gt;, the incident was caused by a change that exposed a memory leak that &lt;em&gt;only occurred under heavy load&lt;/em&gt;.  The lookup service that tracks Google Doc modifications wasn’t properly recycling memory, which eventually caused those machines to restart.  Redundancy systems immediately picked up the slack from these now-offline lookup service machines, but the excessive load caused the replacement machines to run out of memory even faster.  Eventually, the servers couldn’t handle the number of requests that were backed up, which led to the outage.&lt;/p&gt;

&lt;p&gt;The Google engineering team was quick to diagnose the issue and roll out a fix within an hour of the first automated alert.  Unfortunately, Google engineers were unaware of the root cause &lt;em&gt;because&lt;/em&gt; it only occurred while the system was heavily loaded, which shows the importance of expressly testing system resilience when memory usage spikes.&lt;/p&gt;

&lt;h3 id=&quot;performing-a-memory-attack-with-gremlin&quot;&gt;Performing a Memory Attack with Gremlin&lt;/h3&gt;

&lt;p&gt;A Gremlin &lt;strong&gt;Memory Attack&lt;/strong&gt; consumes memory on the targeted machine, making it easy to test how that system and other dependencies behave when memory is unavailable.&lt;/p&gt;

&lt;h4 id=&quot;prerequisites-3&quot;&gt;Prerequisites&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://help.gremlin.com/installation/&quot;&gt;Install Gremlin&lt;/a&gt; on the target machine.&lt;/li&gt;
  &lt;li&gt;Retrieve your &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API Token&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API&lt;/a&gt; &lt;strong&gt;Memory Attack&lt;/strong&gt; accepts the following arguments.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Short Flag&lt;/th&gt;
      &lt;th&gt;Long Flag&lt;/th&gt;
      &lt;th&gt;Purpose&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-g&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--gigabytes&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The amount of memory (in GB) to allocate.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-l&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--length&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Attack duration (in seconds).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-m&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--megabytes&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The amount of memory (in MB) to allocate.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;(Optional)&lt;/em&gt; On the target machine check the current memory usage to establish a baseline prior to executing the attack.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; htop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;&lt;img alt=&quot;HTOP Pre-Attack Memory Usage&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/migrating-cloud-chaotic-embrace/htop-pre-memory-attack-8f541073fd8265545cde63ef1806cf4289a92ae5c2e6efc579be3b4942fa040d.png&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On your local machine create an &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/memory.json&lt;/code&gt; file and paste the following JSON into it, ensuring you change your target &lt;strong&gt;Client&lt;/strong&gt;.  This attack will consume up to &lt;code class=&quot;highlighter-rouge&quot;&gt;0.75 GB&lt;/code&gt; of memory for a total of &lt;code class=&quot;highlighter-rouge&quot;&gt;30&lt;/code&gt; seconds.&lt;/p&gt;

    &lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;memory&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;30&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-g&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;0.75&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;target&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;aws-nginx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Launch the &lt;strong&gt;Memory Attack&lt;/strong&gt; by passing the JSON from &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/memory.json&lt;/code&gt; to the &lt;code class=&quot;highlighter-rouge&quot;&gt;https://api.gremlin.com/v1/attacks/new&lt;/code&gt; API endpoint.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; curl &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$GREMLIN_API_TOKEN&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; https://api.gremlin.com/v1/attacks/new &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;@attacks/memory.json&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;That additional memory is now consumed on the target machine.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; htop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;&lt;img alt=&quot;HTOP Post-Attack Memory Usage&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/migrating-cloud-chaotic-embrace/htop-post-memory-attack-3304d7bc26cdcd93493cb940279150f05d359173b9fe466042d0d8a6c1345036.png&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As always, you can view the &lt;strong&gt;Attack&lt;/strong&gt; within the &lt;a href=&quot;https://app.gremlin.com/attacks&quot;&gt;Gremlin Web UI&lt;/a&gt;.&lt;/p&gt;

    &lt;p&gt;&lt;img alt=&quot;Gremlin Web UI Memory Attack&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/migrating-cloud-chaotic-embrace/web-ui-memory-attack-56e3fb4d678bd41298bd5d8e68a4f90e8bf12ec6fc9f633bdc2af50585249edd.png&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;troubleshooting-io-bottlenecks&quot;&gt;Troubleshooting IO Bottlenecks&lt;/h2&gt;

&lt;p&gt;Due to the proliferation of automatic monitoring and elastic scaling, IO failure may seem like one of the least likely problems within a cloud architecture.  However, even when IO failure isn’t necessarily the &lt;em&gt;root&lt;/em&gt; cause of an outage it is often the &lt;em&gt;result&lt;/em&gt; of another issue.  IO failure typically triggers a &lt;a href=&quot;https://aws.amazon.com/message/680342/&quot;&gt;negative cascading effect&lt;/a&gt; throughout the many other dependent systems.  Moreover, since IO failure is often considered an unlikely event, it’s more common for cloud-based stacks to be particularly vulnerable to IO-induced outages.&lt;/p&gt;

&lt;h3 id=&quot;why-it-matters-amazon-ec2-ebs-and-rds-2011&quot;&gt;Why It Matters: Amazon EC2, EBS, and RDS (2011)&lt;/h3&gt;

&lt;p&gt;Over the course of about a week in April 2011, Amazon EC2 customers suffered a &lt;a href=&quot;https://aws.amazon.com/message/65648/&quot;&gt;significant service outage&lt;/a&gt; when a high percentage of Amazon Elastic Block Store (EBS) volumes within a single Availability Zone in the US East Region became “stuck” – unable to perform read and write operations.  Other service instances attempting to access these “stuck” EBS volumes &lt;em&gt;also&lt;/em&gt; became “stuck” while trying to read or write to the volumes.  In turn, this degraded EBS cluster performance and increased latencies and error rates for EBS API calls across the entire US East Region.&lt;/p&gt;

&lt;p&gt;Understanding the root cause of this outage and everything that was impacted requires a bit of understanding of how Amazon EBS functions.  Normally, an EBS cluster is comprised of a set of EBS nodes that automatically store EBS volume replicas and serve as fast failover redundancies.  If any single EBS volume is out of sync or is unavailable the peer-to-peer failover quickly provisions a new replica to replace the unavailable copy.  EBS nodes communicate over two networks.  The primary network handles high bandwidth connections for normal node-to-node, EC2, and control plane service communications.  The secondary network is a backup network to provide overflow capacity for data replication, but this secondary network is not intended to handle the traffic level of the primary network.&lt;/p&gt;

&lt;p&gt;The outage stemmed from an improperly executed traffic shift while performing a configuration change to the primary network.  Traffic was incorrectly moved onto the low-capacity secondary network.  This had the effect of isolating many of the EBS nodes within the impacted Availability Zone, severing their connections to their replicas.&lt;/p&gt;

&lt;p&gt;While the issue was quickly noticed and addressed, once traffic was reverted back to the primary network the affected EBS nodes swarmed the EBS cluster trying to find available server space to re-mirror data.  This overloaded the cluster and quickly consumed all free capacity, thereby leaving many EBS nodes in a “stuck” state.&lt;/p&gt;

&lt;p class=&quot;notice--success&quot;&gt;In total, around 13% of all volumes in the affected Availability Zone were in a “stuck” state.&lt;/p&gt;

&lt;p&gt;The full &lt;a href=&quot;https://aws.amazon.com/message/65648/&quot;&gt;incident summary report&lt;/a&gt; is a fascinating read if you have the time.  This incident presents a solid real-world example of the dramatic and costly impacts that even an initially minor IO failure can have on a large, distributed system.&lt;/p&gt;

&lt;h3 id=&quot;performing-an-io-attack-with-gremlin&quot;&gt;Performing an IO Attack with Gremlin&lt;/h3&gt;

&lt;p&gt;Gremlin’s &lt;strong&gt;IO Attack&lt;/strong&gt; performs rapid read and/or write actions on the targeted system volume.&lt;/p&gt;

&lt;h4 id=&quot;prerequisites-4&quot;&gt;Prerequisites&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://help.gremlin.com/installation/&quot;&gt;Install Gremlin&lt;/a&gt; on the target machine.&lt;/li&gt;
  &lt;li&gt;Retrieve your &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API Token&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A &lt;a href=&quot;https://help.gremlin.com/api/&quot;&gt;Gremlin API&lt;/a&gt; &lt;strong&gt;IO Attack&lt;/strong&gt; accepts the following arguments.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Short Flag&lt;/th&gt;
      &lt;th&gt;Long Flag&lt;/th&gt;
      &lt;th&gt;Purpose&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-c&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--block-count&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The number of blocks read or written by workers.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-d&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--dir&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The directory that temporary files will be written to.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-l&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--length&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Attack duration (in seconds).&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-m&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--mode&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Specifies if workers are in read (&lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt;), write (&lt;code class=&quot;highlighter-rouge&quot;&gt;w&lt;/code&gt;), or read+write (&lt;code class=&quot;highlighter-rouge&quot;&gt;rw&lt;/code&gt;) mode.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-s&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--block-size&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Size of blocks (in KB) that are read or written by workers.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-w&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--workers&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;The number of concurrent workers.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;On your local machine create an &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/io.json&lt;/code&gt; file and paste the following JSON into it.  Change the target &lt;strong&gt;Client&lt;/strong&gt; as necessary.  This &lt;strong&gt;IO Attack&lt;/strong&gt; creates two workers that will perform both reads and writes during the &lt;code class=&quot;highlighter-rouge&quot;&gt;45-second&lt;/code&gt; attack.&lt;/p&gt;

    &lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;command&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;io&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;args&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;45&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/tmp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-w&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-m&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rw&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;target&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;exact&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;aws-nginx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
     &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
 &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Launch the &lt;strong&gt;IO Attack&lt;/strong&gt; by passing the JSON from &lt;code class=&quot;highlighter-rouge&quot;&gt;attacks/io.json&lt;/code&gt; to the &lt;code class=&quot;highlighter-rouge&quot;&gt;https://api.gremlin.com/v1/attacks/new&lt;/code&gt; API endpoint.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; curl &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$GREMLIN_API_TOKEN&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; https://api.gremlin.com/v1/attacks/new &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;@attacks/io.json&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On the target machine verify that the attack is running and that IO is currently overloaded.&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;iotop &lt;span class=&quot;nt&quot;&gt;-aoP&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# OUTPUT&lt;/span&gt;
 Total DISK READ :       0.00 B/s | Total DISK WRITE :       3.92 M/s
 Actual DISK READ:       0.00 B/s | Actual DISK WRITE:      15.77 M/s
 PID  PRIO  USER       DISK READ  DISK WRITE  SWAPIN     IO&amp;gt;     COMMAND
 323   be/3 root          0.00 B     68.00 K  0.00 % 71.28 %   &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;jbd2/xvda1-8]
 20030 be/4 gremlin       0.00 B    112.15 M  0.00 % 17.11 %   gremlin attack io &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; 45 &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; /tmp &lt;span class=&quot;nt&quot;&gt;-w&lt;/span&gt; 2 &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; rw &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; 4 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You can also view the &lt;strong&gt;Attack&lt;/strong&gt; within the &lt;a href=&quot;https://app.gremlin.com/attacks&quot;&gt;Gremlin Web UI&lt;/a&gt;.&lt;/p&gt;

    &lt;p&gt;&lt;img alt=&quot;Gremlin Web UI IO Attack&quot; src=&quot;/gremlin-blog-posts/assets/chaos-engineering/migrating-cloud-chaotic-embrace/web-ui-io-attack-ff90b8f038d7908f60d63c251445b438473139c381d0ff2dab50061f5261a656.png&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;what-comes-next&quot;&gt;What Comes Next?&lt;/h2&gt;

&lt;p&gt;This article explored a number of common issues and outages related to failed migrations and upgrade procedures. As impactful and expensive as those outages may have been, their existence shouldn’t dissuade you from making the move to the cloud. A distributed architecture allows you to enjoy faster release cycles and, in general, increased developer productivity.&lt;/p&gt;

&lt;p&gt;Instead, the occurrence of migration issues for even the biggest organizations in the industry illustrates the necessity of proper resilience testing.  Chaos Engineering is a critical piece of that finished and fully-resilient puzzle.  Planning ahead and running Chaos Experiments on your systems, both prior to and during migration, will help ensure you’re creating the most stable, robust, and resilient system possible.&lt;/p&gt;</content><author><name>Gabe Wyatt</name></author><category term="migration" /><category term="experiment" /><category term="outage" /><summary type="html">Why organizations planning to migrate to the cloud should embrace Chaos Engineering as a thoughtful strategy to avoid pain down the road.</summary></entry></feed>